#!/usr/bin/env python3
# ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ - Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ

import re
import requests
import tempfile
import subprocess
import platform
import threading
import time
from loguru import logger

# Ù‚Ø§Ù…ÙˆØ³ Ø´Ø§Ù…Ù„ Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Ø·Ù‚
ARABIC_PRONUNCIATION_DICT = {
    # Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù…Ø­Ø·Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    "Ù„Ø§Ø¹Ø±Ø¨ÙŠ": "Ø³ÙØ§Ø¨ÙÙƒ",
    "Ø³Ø¨Ùƒ": "Ø³ÙØ§Ø¨ÙÙƒ", 
    "Ù„Ø§Ø¹Ø±Ø¨Ù‰": "Ø³ÙØ§Ø¨ÙÙƒ",
    "SABIC": "Ø³ÙØ§Ø¨ÙÙƒ",
    "sabic": "Ø³ÙØ§Ø¨ÙÙƒ",
    
    # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø­Ø·Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    "Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡": "Ø§Ù„Ù’Ù…ÙÙ„ÙÙƒÙ’ Ø¹ÙØ¨Ù’Ø¯ÙØ§Ù„Ù„Ù‡",
    "Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯": "Ø§Ù„Ù’Ù…ÙÙ„ÙÙƒÙ’ ÙÙÙ‡Ù’Ø¯", 
    "Ø§Ù„Ø£Ù…ÙŠØ± Ù…Ø­Ù…Ø¯": "Ø§Ù„Ø£ÙÙ…ÙÙŠØ±Ù’ Ù…ÙØ­ÙÙ…ÙÙ‘Ø¯",
    "Ø§Ù„Ø±ÙŠØ§Ø¶": "Ø§Ù„Ø±ÙÙ‘ÙŠÙØ§Ø¶Ù’",
    "Ø§Ù„Ù…Ø·Ø§Ø±": "Ø§Ù„Ù’Ù…ÙØ·ÙØ§Ø±Ù’",
    "Ø§Ù„Ø¯Ø±Ø¹ÙŠØ©": "Ø§Ù„Ø¯ÙÙ‘Ø±Ù’Ø¹ÙÙŠÙÙ‘Ø©",
    "Ø§Ù„Ù†ÙˆØ±": "Ø§Ù„Ù†ÙÙ‘ÙˆØ±Ù’",
    "Ø§Ù„ÙÙŠØµÙ„ÙŠØ©": "Ø§Ù„Ù’ÙÙÙŠÙ’ØµÙÙ„ÙÙŠÙÙ‘Ø©",
    "Ø§Ù„Ù…Ø±Ø¨Ø¹": "Ø§Ù„Ù’Ù…ÙØ±ÙØ¨ÙÙ‘Ø¹",
    "Ø§Ù„Ø­ÙƒÙˆÙ…Ø©": "Ø§Ù„Ù’Ø­ÙÙƒÙÙˆÙ…ÙØ©",
    "Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©": "Ø§Ù„Ù’Ø¬ÙØ§Ù…ÙØ¹ÙØ©",
    "Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰": "Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙØ´Ù’ÙÙÙ‰",
    
    # ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… - Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø¨Ø±Ø©
    "Ù…Ø­Ø·Ø©": "Ù…ÙØ­ÙØ·ÙÙ‘Ø©",
    "Ù…Ø·Ø¹Ù…": "Ù…ÙØ·Ù’Ø¹ÙÙ…", 
    "Ù…Ø·Ø§Ø¹Ù…": "Ù…ÙØ·ÙØ§Ø¹ÙÙ…",
    "Ø³Ø±Ø§Ø¬": "Ø³ÙØ±ÙØ§Ø¬",
    "ØªÙØ¶Ù„": "ØªÙÙÙØ¶ÙÙ‘Ù„",
    "Ù…Ø±Ø­Ø¨Ø§": "Ù…ÙØ±Ù’Ø­ÙØ¨Ø§Ù‹",
    "Ù…Ø±Ø­Ø¨Ø§Ù‹": "Ù…ÙØ±Ù’Ø­ÙØ¨Ø§Ù‹",
    "Ø§Ù‡Ù„Ø§": "Ø£ÙÙ‡Ù’Ù„Ø§Ù‹",
    "Ø£Ù‡Ù„Ø§": "Ø£ÙÙ‡Ù’Ù„Ø§Ù‹ ÙˆÙØ³ÙÙ‡Ù’Ù„Ø§Ù‹",
    "Ø§Ù‚Ø±Ø¨": "Ø£ÙÙ‚Ù’Ø±ÙØ¨",
    "Ù…Ø³Ø§Ø±": "Ù…ÙØ³ÙØ§Ø±",
    "Ø·Ø±ÙŠÙ‚": "Ø·ÙØ±ÙÙŠÙ‚",
    "Ø®Ø±ÙŠØ·Ø©": "Ø®ÙØ±ÙÙŠØ·ÙØ©",
    "Ø§Ø¶ØºØ·": "Ø§Ø¶Ù’ØºÙØ·",
    "Ø¹Ø±Ø¶": "Ø¹ÙØ±Ù’Ø¶",
    "Ø´ÙƒØ±Ø§": "Ø´ÙÙƒÙ’Ø±Ø§Ù‹",
    "Ø´ÙƒØ±Ù‹Ø§": "Ø´ÙÙƒÙ’Ø±Ø§Ù‹ Ù„ÙÙƒ",
    "Ø¹ÙÙˆØ§": "Ø¹ÙÙÙ’ÙˆØ§Ù‹",
    "Ø¹ÙÙˆØ§Ù‹": "Ø¹ÙÙÙ’ÙˆØ§Ù‹",
    
    # Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ù‡Ø°Ø¨Ø© ÙˆÙ„Ø·ÙŠÙØ©
    "Ù…Ø§ Ø§Ø³Ù…": "Ù…ÙØ§ Ø§Ø³Ù’Ù…Ù",
    "ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ": "ÙƒÙÙŠÙ’ÙÙ ÙŠÙÙ…Ù’ÙƒÙÙ†ÙÙ†ÙŠ",
    "ÙŠØ³Ø¹Ø¯Ù†ÙŠ": "ÙŠÙØ³Ù’Ø¹ÙØ¯ÙÙ†ÙŠ",
    "Ø¨ÙƒÙ„ Ø³Ø±ÙˆØ±": "Ø¨ÙÙƒÙÙ„ÙÙ‘ Ø³ÙØ±ÙÙˆØ±",
    "Ù„Ø§ Ù…Ø´ÙƒÙ„Ø©": "Ù„Ø§ Ù…ÙØ´Ù’ÙƒÙÙ„ÙØ©",
    
    # Ù…Ø·Ø§Ø¹Ù… Ø´Ø§Ø¦Ø¹Ø©
    "Ø§Ù„Ø¨ÙŠÙƒ": "Ø§Ù„Ù’Ø¨ÙÙŠÙƒ",
    "Ø§Ù„Ø·Ø§Ø²Ø¬": "Ø§Ù„Ø·ÙÙ‘Ø§Ø²ÙØ¬",
    "ÙƒÙˆØ¯Ùˆ": "ÙƒÙÙˆØ¯ÙÙˆ",
    "Ø§Ù„Ø´Ø±ÙØ©": "Ø§Ù„Ø´ÙÙ‘Ø±Ù’ÙÙØ©",
    "Ø§Ù„Ù†Ø§ÙÙˆØ±Ø©": "Ø§Ù„Ù†ÙÙ‘Ø§ÙÙÙˆØ±ÙØ©",
    "Ø§Ù„Ø´ÙŠÙ": "Ø§Ù„Ø´ÙÙ‘ÙŠÙ",
    "Ø³ØªØ§Ø±Ø¨ÙƒØ³": "Ø³Ù’ØªÙØ§Ø±Ù’Ø¨ÙÙƒÙ’Ø³",
    "Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²": "Ù…ÙØ§ÙƒÙ’Ø¯ÙÙˆÙ†ÙØ§Ù„Ù’Ø¯Ø²",
    "ÙƒÙ†ØªØ§ÙƒÙŠ": "ÙƒÙÙ†Ù’ØªÙØ§ÙƒÙÙŠ",
    "Ø¨ÙŠØªØ²Ø§ Ù‡Øª": "Ø¨ÙÙŠØªÙ’Ø²ÙØ§ Ù‡ÙØª",
    "Ø¯ÙˆÙ…ÙŠÙ†ÙˆØ²": "Ø¯ÙÙˆÙ…ÙÙŠÙ†ÙÙˆØ²",
    
    # Ø£Ø±Ù‚Ø§Ù… ÙˆØ£Ø¹Ø¯Ø§Ø¯
    "ÙˆØ§Ø­Ø¯": "ÙˆÙØ§Ø­ÙØ¯",
    "Ø§Ø«Ù†ÙŠÙ†": "Ø§Ø«Ù’Ù†ÙÙŠÙ’Ù†", 
    "Ø«Ù„Ø§Ø«Ø©": "Ø«ÙÙ„ÙØ§Ø«ÙØ©",
    "Ø§Ø±Ø¨Ø¹Ø©": "Ø£ÙØ±Ù’Ø¨ÙØ¹ÙØ©",
    "Ø®Ù…Ø³Ø©": "Ø®ÙÙ…Ù’Ø³ÙØ©",
    "Ø³ØªØ©": "Ø³ÙØªÙÙ‘Ø©",
    "Ø³Ø¨Ø¹Ø©": "Ø³ÙØ¨Ù’Ø¹ÙØ©",
    "Ø«Ù…Ø§Ù†ÙŠØ©": "Ø«ÙÙ…ÙØ§Ù†ÙÙŠÙØ©",
    "ØªØ³Ø¹Ø©": "ØªÙØ³Ù’Ø¹ÙØ©",
    "Ø¹Ø´Ø±Ø©": "Ø¹ÙØ´Ù’Ø±ÙØ©",
    
    # ÙƒÙ„Ù…Ø§Øª Ù…Ø³Ø§Ø¹Ø¯Ø©
    "Ù‡Ø°Ø§": "Ù‡ÙØ°ÙØ§",
    "Ù‡Ø°Ù‡": "Ù‡ÙØ°ÙÙ‡Ù", 
    "Ø°Ù„Ùƒ": "Ø°ÙÙ„ÙÙƒ",
    "ØªÙ„Ùƒ": "ØªÙÙ„Ù’Ùƒ",
    "Ø§Ù„Ù‰": "Ø¥ÙÙ„ÙÙ‰",
    "Ø¥Ù„Ù‰": "Ø¥ÙÙ„ÙÙ‰",
    "Ù…Ù†": "Ù…ÙÙ†",
    "ÙÙŠ": "ÙÙÙŠ",
    "Ø¹Ù„Ù‰": "Ø¹ÙÙ„ÙÙ‰",
    "Ø¹Ù†Ø¯": "Ø¹ÙÙ†Ù’Ø¯",
    "Ø¨Ø¹Ø¯": "Ø¨ÙØ¹Ù’Ø¯",
    "Ù‚Ø¨Ù„": "Ù‚ÙØ¨Ù’Ù„",
    "ÙÙˆÙ‚": "ÙÙÙˆÙ’Ù‚",
    "ØªØ­Øª": "ØªÙØ­Ù’Øª",
    "ÙŠÙ…ÙŠÙ†": "ÙŠÙÙ…ÙÙŠÙ†",
    "ÙŠØ³Ø§Ø±": "ÙŠÙØ³ÙØ§Ø±",
    "Ø´Ù…Ø§Ù„": "Ø´ÙÙ…ÙØ§Ù„",
    "Ø¬Ù†ÙˆØ¨": "Ø¬ÙÙ†ÙÙˆØ¨",
    "Ø´Ø±Ù‚": "Ø´ÙØ±Ù’Ù‚",
    "ØºØ±Ø¨": "ØºÙØ±Ù’Ø¨",
}

# Ù‚ÙˆØ§Ø¹Ø¯ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø±ÙƒØ§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
DIACRITIC_RULES = [
    # Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙ
    (r'\bØ§Ù„([Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ])', r'Ø§Ù„Ù’\1'),
    (r'\bØ§Ù„([Ø£Ø¥])', r'Ø§Ù„Ù’\1'),
    
    # Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±
    (r'\bÙ…Ù†\s+', r'Ù…ÙÙ† '),
    (r'\bØ¥Ù„Ù‰\s+', r'Ø¥ÙÙ„ÙÙ‰ '),
    (r'\bÙÙŠ\s+', r'ÙÙÙŠ '),
    (r'\bØ¹Ù„Ù‰\s+', r'Ø¹ÙÙ„ÙÙ‰ '),
    (r'\bØ¹Ù†\s+', r'Ø¹ÙÙ† '),
    
    # Ø¶Ù…Ø§Ø¦Ø±
    (r'\bÙ‡Ùˆ\b', r'Ù‡ÙÙˆÙ'),
    (r'\bÙ‡ÙŠ\b', r'Ù‡ÙÙŠÙ'),
    (r'\bØ£Ù†Øª\b', r'Ø£ÙÙ†Ù’Øª'),
    (r'\bØ£Ù†ØªÙ…\b', r'Ø£ÙÙ†Ù’ØªÙÙ…'),
    (r'\bÙ†Ø­Ù†\b', r'Ù†ÙØ­Ù’Ù†'),
    
    # Ø£ÙØ¹Ø§Ù„ Ø´Ø§Ø¦Ø¹Ø© Ù…Ø¹ Ù†Ø¨Ø±Ø© ÙˆØ¯ÙˆØ¯Ø©
    (r'\bÙŠÙƒÙˆÙ†\b', r'ÙŠÙÙƒÙÙˆÙ†'),
    (r'\bÙƒØ§Ù†\b', r'ÙƒÙØ§Ù†'),
    (r'\bÙŠØ±ÙŠØ¯\b', r'ÙŠÙØ±ÙÙŠØ¯'),
    (r'\bØ£Ø±ÙŠØ¯\b', r'Ø£ÙØ±ÙÙŠØ¯'),
    (r'\bØ§Ø°Ù‡Ø¨\b', r'Ø§Ø°Ù’Ù‡ÙØ¨'),
    (r'\bØªØ¹Ø§Ù„\b', r'ØªÙØ¹ÙØ§Ù„'),
    (r'\bØ§Ù†ØªØ¸Ø±\b', r'Ø§Ù†Ù’ØªÙØ¸ÙØ±'),
]

def enhance_arabic_pronunciation(text: str) -> str:
    """
    Enhance Arabic text for better pronunciation with TTS systems
    """
    # Common pronunciation fixes
    replacements = {
        # Station names
        'Ù„Ø§Ø¹Ø±Ø¨ÙŠ': 'Ù„Ø§ Ø¹Ø±Ø¨ÙŠ',
        'Ø³Ø§Ø¨Ùƒ': 'Ø³ÙØ§Ø¨ÙÙƒ',
        'Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡': 'Ø§Ù„Ù’Ù…ÙÙ„ÙÙƒ Ø¹ÙØ¨Ù’Ø¯ Ø§Ù„Ù„ÙÙ‘Ù‡',
        'Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯': 'Ø§Ù„Ù’Ù…ÙÙ„ÙÙƒ ÙÙÙ‡Ù’Ø¯',
        'Ø§Ù„Ù…Ù„Ùƒ Ø®Ø§Ù„Ø¯': 'Ø§Ù„Ù’Ù…ÙÙ„ÙÙƒ Ø®ÙØ§Ù„ÙØ¯',
        
        # Restaurant names
        'Ø§Ù„Ø¨ÙŠÙƒ': 'Ø§Ù„Ù’Ø¨ÙÙŠÙƒ',
        'ÙƒÙˆØ¯Ùˆ': 'ÙƒÙÙˆØ¯ÙÙˆ',
        'Ù‡Ø±ÙÙŠ': 'Ù‡ÙØ±Ù’ÙÙÙŠ',
        'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²': 'Ù…ÙØ§ÙƒÙ’Ø¯ÙÙˆÙ†ÙØ§Ù„Ù’Ø¯Ø²',
        'ÙƒÙ†ØªØ§ÙƒÙŠ': 'ÙƒÙÙ†Ù’ØªÙØ§ÙƒÙÙŠ',
        'Ø¨ÙŠØªØ²Ø§ Ù‡Øª': 'Ø¨ÙÙŠØªÙ’Ø²ÙØ§ Ù‡ÙØª',
        'Ø¯ÙˆÙ…ÙŠÙ†ÙˆØ²': 'Ø¯ÙÙˆÙ…ÙÙŠÙ†ÙÙˆØ²',
        'ØµØ¨ ÙˆØ§ÙŠ': 'ØµÙØ¨ ÙˆÙØ§ÙŠ',
        'Ø¨Ø±Ø¬Ø± ÙƒÙ†Ø¬': 'Ø¨ÙØ±Ù’Ø¬ÙØ± ÙƒÙÙ†Ù’Ø¬',
        'Ø§Ù„Ø·Ø§Ø²Ø¬': 'Ø§Ù„Ø·ÙÙ‘Ø§Ø²ÙØ¬',
        
        # Common words
        'Ù…Ø·Ø¹Ù…': 'Ù…ÙØ·Ù’Ø¹ÙÙ…',
        'Ù…Ø­Ø·Ø©': 'Ù…ÙØ­ÙØ·ÙÙ‘Ø©',
        'Ù…Ø³Ø§Ø±': 'Ù…ÙØ³ÙØ§Ø±',
        'Ø£Ù‚Ø±Ø¨': 'Ø£ÙÙ‚Ù’Ø±ÙØ¨',
        'Ø¥Ù„Ù‰': 'Ø¥ÙÙ„ÙÙ‰',
        'Ù…Ù†': 'Ù…ÙÙ†',
        'Ø§Ù„Ø±ÙŠØ§Ø¶': 'Ø§Ù„Ø±ÙÙ‘ÙŠÙØ§Ø¶',
        'Ø§Ù„Ù…ØªØ±Ùˆ': 'Ø§Ù„Ù’Ù…ÙØªÙ’Ø±ÙÙˆ',
        
        # Directions and instructions
        'Ø§Ø¶ØºØ·': 'Ø§Ø¶Ù’ØºÙØ·',
        'Ø¹Ù„Ù‰': 'Ø¹ÙÙ„ÙÙ‰',
        'Ø¥Ø¸Ù‡Ø§Ø±': 'Ø¥ÙØ¸Ù’Ù‡ÙØ§Ø±',
        'Ø§Ù„Ø®Ø±ÙŠØ·Ø©': 'Ø§Ù„Ù’Ø®ÙØ±ÙÙŠØ·ÙØ©',
        'Ù„Ø¹Ø±Ø¶': 'Ù„ÙØ¹ÙØ±Ù’Ø¶',
        'ØªÙØ¶Ù„': 'ØªÙÙÙØ¶ÙÙ‘Ù„',
        'Ù…Ø§ Ø§Ø³Ù…': 'Ù…ÙØ§ Ø§Ø³Ù’Ù…',
        'Ù…Ù† ÙØ¶Ù„Ùƒ': 'Ù…ÙÙ† ÙÙØ¶Ù’Ù„ÙÙƒ',
        
        # Greetings and responses
        'Ù…Ø±Ø­Ø¨Ø§': 'Ù…ÙØ±Ù’Ø­ÙØ¨ÙØ§Ù‹',
        'Ø£Ù‡Ù„Ø§': 'Ø£ÙÙ‡Ù’Ù„Ø§Ù‹',
        'ÙˆØ³Ù‡Ù„Ø§': 'ÙˆÙØ³ÙÙ‡Ù’Ù„Ø§Ù‹',
        'Ø´ÙƒØ±Ø§': 'Ø´ÙÙƒÙ’Ø±ÙØ§Ù‹',
        'Ø¹ÙÙˆØ§': 'Ø¹ÙÙÙ’ÙˆÙØ§Ù‹',
        'Ù†Ø¹Ù…': 'Ù†ÙØ¹ÙÙ…',
        'Ù„Ø§': 'Ù„ÙØ§',
        
        # System responses
        'Ø¬Ø§Ù‡Ø²': 'Ø¬ÙØ§Ù‡ÙØ²',
        'Ù„Ù„Ø§Ø³ØªÙ…Ø§Ø¹': 'Ù„ÙÙ„Ø§ÙØ³Ù’ØªÙÙ…ÙØ§Ø¹',
        'Ø­Ø§ÙˆÙ„': 'Ø­ÙØ§ÙˆÙÙ„',
        'Ù…Ø±Ø© Ø£Ø®Ø±Ù‰': 'Ù…ÙØ±ÙÙ‘Ø© Ø£ÙØ®Ù’Ø±ÙÙ‰',
        'Ù„Ù… Ø£Ø³Ù…Ø¹': 'Ù„ÙÙ… Ø£ÙØ³Ù’Ù…ÙØ¹',
        'Ø´ÙŠØ¦Ø§': 'Ø´ÙÙŠÙ’Ø¦ÙØ§Ù‹',
        'Ù„Ù… Ø£ÙÙ‡Ù…': 'Ù„ÙÙ… Ø£ÙÙÙ’Ù‡ÙÙ…',
        'Ø·Ù„Ø¨Ùƒ': 'Ø·ÙÙ„ÙØ¨ÙÙƒ',
        'Ù„Ù… Ø£Ø¹Ø±Ù': 'Ù„ÙÙ… Ø£ÙØ¹Ù’Ø±ÙÙ',
        'Ø§Ø³Ù… Ø§Ù„Ù…Ø·Ø¹Ù…': 'Ø§Ø³Ù’Ù… Ø§Ù„Ù’Ù…ÙØ·Ù’Ø¹ÙÙ…',
        
        # Numbers (commonly mispronounced)
        'ÙˆØ§Ø­Ø¯': 'ÙˆÙØ§Ø­ÙØ¯',
        'Ø§Ø«Ù†Ø§Ù†': 'Ø§Ø«Ù’Ù†ÙØ§Ù†',
        'Ø«Ù„Ø§Ø«Ø©': 'Ø«ÙÙ„ÙØ§Ø«ÙØ©',
        'Ø£Ø±Ø¨Ø¹Ø©': 'Ø£ÙØ±Ù’Ø¨ÙØ¹ÙØ©',
        'Ø®Ù…Ø³Ø©': 'Ø®ÙÙ…Ù’Ø³ÙØ©',
        'Ø³ØªØ©': 'Ø³ÙØªÙÙ‘Ø©',
        'Ø³Ø¨Ø¹Ø©': 'Ø³ÙØ¨Ù’Ø¹ÙØ©',
        'Ø«Ù…Ø§Ù†ÙŠØ©': 'Ø«ÙÙ…ÙØ§Ù†ÙÙŠÙØ©',
        'ØªØ³Ø¹Ø©': 'ØªÙØ³Ù’Ø¹ÙØ©',
        'Ø¹Ø´Ø±Ø©': 'Ø¹ÙØ´ÙØ±ÙØ©'
    }
    
    enhanced = text
    
    # Apply replacements
    for original, enhanced_version in replacements.items():
        enhanced = enhanced.replace(original, enhanced_version)
    
    # Add pauses for better flow
    enhanced = re.sub(r'([.!?])', r'\1 ', enhanced)
    enhanced = re.sub(r'ØŒ', 'ØŒ ', enhanced)
    
    # Clean up extra spaces
    enhanced = re.sub(r'\s+', ' ', enhanced).strip()
    
    return enhanced

def remove_diacritics(text: str) -> str:
    """
    Remove Arabic diacritics for cleaner display
    """
    diacritics = (
        '\u064B'  # Fathatan
        '\u064C'  # Dammatan
        '\u064D'  # Kasratan
        '\u064E'  # Fatha
        '\u064F'  # Damma
        '\u0650'  # Kasra
        '\u0651'  # Shadda
        '\u0652'  # Sukun
        '\u0653'  # Maddah
        '\u0654'  # Hamza above
        '\u0655'  # Hamza below
        '\u0656'  # Subscript alef
        '\u0657'  # Inverted damma
        '\u0658'  # Mark noon ghunna
        '\u0659'  # Zwarakay
        '\u065A'  # Vowel sign small v
        '\u065B'  # Vowel sign inverted small v
        '\u065C'  # Vowel sign dot below
        '\u065D'  # Reversed damma
        '\u065E'  # Fatha with two dots
        '\u065F'  # Wavy hamza below
    )
    
    return ''.join(char for char in text if char not in diacritics)

def create_optimized_voice_settings():
    """
    Create optimized voice settings for ElevenLabs Arabic TTS
    """
    return {
        "stability": 0.75,        # Good balance for Arabic
        "similarity_boost": 0.85, # High similarity for consistency
        "style": 0.2,            # Moderate style for natural speech
        "use_speaker_boost": True # Enhance speaker characteristics
    }

def normalize_restaurant_name(name: str) -> str:
    """
    Normalize restaurant names for better matching
    """
    # Remove common prefixes
    name = re.sub(r'^(Ù…Ø·Ø¹Ù…|Ù…Ù‚Ù‡Ù‰|ÙƒØ§ÙÙŠÙ‡|ÙƒØ§ÙÙŠØ©)\s*', '', name, flags=re.IGNORECASE)
    
    # Normalize spacing
    name = re.sub(r'\s+', ' ', name).strip()
    
    # Common name variations
    variations = {
        'Ø§Ù„Ø¨ÙŠÙƒ': ['Ø¨ÙŠÙƒ', 'Ø§Ù„Ø¨Ø§Ùƒ', 'Ø¨Ø§Ùƒ'],
        'ÙƒÙˆØ¯Ùˆ': ['ÙƒÙˆØ¯ÙˆÙˆ', 'ÙƒØ¯Ùˆ'],
        'Ù‡Ø±ÙÙŠ': ['Ù‡Ø±ÙÙ‰', 'Ù‡Ø§Ø±ÙÙŠ'],
        'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²': ['Ù…Ø§Ùƒ', 'Ù…ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²', 'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯'],
        'ÙƒÙ†ØªØ§ÙƒÙŠ': ['ÙƒÙ†ØªÙƒÙŠ', 'ÙƒÙ†ØªØ§ÙƒÙ‰'],
        'Ø¨ÙŠØªØ²Ø§ Ù‡Øª': ['Ø¨ÙŠØªØ²Ø§', 'Ø¨ÙŠØªØ²Ø§Ù‡Øª'],
        'Ø§Ù„Ø·Ø§Ø²Ø¬': ['Ø·Ø§Ø²Ø¬']
    }
    
    # Check for variations
    name_lower = name.lower()
    for standard, variants in variations.items():
        if name_lower in [v.lower() for v in variants]:
            return standard
    
    return name

def extract_restaurant_patterns():
    """
    Return comprehensive patterns for restaurant name extraction
    """
    return [
        # Direct restaurant mention
        r"Ù…Ø·Ø¹Ù…\s*([\u0600-\u06FF0-9'\-\s]+)",
        
        # Popular restaurants (exact matches)
        r"(Ø§Ù„Ø¨ÙŠÙƒ|Ø§Ù„Ø·Ø§Ø²Ø¬|ÙƒÙˆØ¯Ùˆ|Ù‡Ø±ÙÙŠ|Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²|ÙƒÙ†ØªØ§ÙƒÙŠ|Ø¨ÙŠØªØ²Ø§\s*Ù‡Øª|Ø¯ÙˆÙ…ÙŠÙ†ÙˆØ²|ØµØ¨\s*ÙˆØ§ÙŠ|Ø¨Ø±Ø¬Ø±\s*ÙƒÙ†Ø¬)",
        
        # Intent-based patterns
        r"Ø£Ø±ÙŠØ¯\s*(?:Ø£Ù†\s*Ø£Ø°Ù‡Ø¨\s*Ø¥Ù„Ù‰\s*)?([\u0600-\u06FF0-9'\-\s]+)",
        r"Ø¥Ù„Ù‰\s*([\u0600-\u06FF0-9'\-\s]+)",
        r"Ø¹Ù†Ø¯\s*([\u0600-\u06FF0-9'\-\s]+)",
        r"ÙÙŠ\s*([\u0600-\u06FF0-9'\-\s]+)",
        
        # General Arabic text (fallback)
        r"([\u0600-\u06FF]{3,}(?:\s+[\u0600-\u06FF]+)*)"
    ]

def get_restaurant_shortcuts():
    """
    Return dictionary of restaurant shortcuts for quick matching
    """
    return {
        'Ø§Ù„Ø¨ÙŠÙƒ': 'Ø§Ù„Ø¨ÙŠÙƒ',
        'Ø¨ÙŠÙƒ': 'Ø§Ù„Ø¨ÙŠÙƒ',
        'ÙƒÙˆØ¯Ùˆ': 'ÙƒÙˆØ¯Ùˆ',
        'Ù‡Ø±ÙÙŠ': 'Ù‡Ø±ÙÙŠ',
        'Ø§Ù„Ø·Ø§Ø²Ø¬': 'Ø§Ù„Ø·Ø§Ø²Ø¬',
        'Ø·Ø§Ø²Ø¬': 'Ø§Ù„Ø·Ø§Ø²Ø¬',
        'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²': 'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²',
        'Ù…Ø§Ùƒ': 'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²',
        'Ù…ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²': 'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²',
        'ÙƒÙ†ØªØ§ÙƒÙŠ': 'ÙƒÙ†ØªØ§ÙƒÙŠ',
        'ÙƒÙ†ØªÙƒÙŠ': 'ÙƒÙ†ØªØ§ÙƒÙŠ',
        'Ø¨ÙŠØªØ²Ø§': 'Ø¨ÙŠØªØ²Ø§ Ù‡Øª',
        'Ø¨ÙŠØªØ²Ø§Ù‡Øª': 'Ø¨ÙŠØªØ²Ø§ Ù‡Øª',
        'Ø¯ÙˆÙ…ÙŠÙ†ÙˆØ²': 'Ø¯ÙˆÙ…ÙŠÙ†ÙˆØ²',
        'ØµØ¨ ÙˆØ§ÙŠ': 'ØµØ¨ ÙˆØ§ÙŠ',
        'ØµØ¨ÙˆØ§ÙŠ': 'ØµØ¨ ÙˆØ§ÙŠ',
        'Ø¨Ø±Ø¬Ø± ÙƒÙ†Ø¬': 'Ø¨Ø±Ø¬Ø± ÙƒÙ†Ø¬',
        'Ø¨Ø±Ø¬Ø±ÙƒÙ†Ø¬': 'Ø¨Ø±Ø¬Ø± ÙƒÙ†Ø¬'
    }

def clean_extracted_text(text: str) -> str:
    """
    Clean extracted restaurant text
    """
    if not text:
        return ""
    
    # Remove common prefixes and suffixes
    text = re.sub(r'^(Ù…Ø·Ø¹Ù…|Ù…Ù‚Ù‡Ù‰|ÙƒØ§ÙÙŠÙ‡|Ø¥Ù„Ù‰|Ù…Ù†|ÙÙŠ|Ø¹Ù†Ø¯)\s*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s*(Ù…Ù† ÙØ¶Ù„Ùƒ|Ù„Ùˆ Ø³Ù…Ø­Øª|Ø´ÙƒØ±Ø§)$', '', text, flags=re.IGNORECASE)
    
    # Normalize whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Remove very short or common words
    excluded_words = ['Ù†Ø¹Ù…', 'Ù„Ø§', 'Ø´ÙƒØ±Ø§', 'Ø£Ù‡Ù„Ø§', 'Ù…Ø±Ø­Ø¨Ø§', 'Ø§Ù„Ø³Ù„Ø§Ù…', 'Ø¹Ù„ÙŠÙƒÙ…', 'ÙˆØ¹Ù„ÙŠÙƒÙ…']
    if text.lower() in [word.lower() for word in excluded_words]:
        return ""
    
    return text

# Test function
def test_enhancements():
    """
    Test the enhancement functions
    """
    test_cases = [
        "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ø­Ø·Ø© Ø³Ø§Ø¨Ùƒ",
        "Ù…Ø­Ø·Ø© Ù„Ø§Ø¹Ø±Ø¨ÙŠ",
        "Ø£Ù‚Ø±Ø¨ Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ø·Ø¹Ù… Ø§Ù„Ø¨ÙŠÙƒ",
        "ØªÙØ¶Ù„ Ù…Ø§ Ø§Ø³Ù… Ø§Ù„Ù…Ø·Ø¹Ù…",
        "Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø±ÙŠØ§Ø¶"
    ]
    
    print("ğŸ§ª Testing Arabic enhancements:")
    print("=" * 50)
    
    for test in test_cases:
        enhanced = enhance_arabic_pronunciation(test)
        clean = remove_diacritics(enhanced)
        print(f"Original: {test}")
        print(f"Enhanced: {enhanced}")
        print(f"Clean:    {clean}")
        print("-" * 30)

if __name__ == "__main__":
    test_enhancements()