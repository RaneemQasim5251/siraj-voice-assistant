#!/usr/bin/env python3
"""
Siraj - Clean Gemini Live Solution with Face Detection
Advanced Arabic Voice Assistant using Gemini Live API for bidirectional audio
Features:
- Gemini Live API integration for real-time voice conversations
- Background face detection for automatic greeting (no camera window shown)
- Enhanced Arabic text processing and pronunciation
- Restaurant search and navigation for Riyadh Metro
- RAG system integration for comprehensive assistance
- Clean, modern GUI with video avatar display
"""

import os
import re
import sys
import threading
import time
import asyncio
import sqlite3
from collections import deque
from threading import Lock
from typing import List, Dict

import cv2
import pandas as pd
import PySimpleGUI as sg
import geopandas as gpd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pygame
import soundfile as sf
import tempfile
import webbrowser

from shapely.geometry import LineString, Point, MultiLineString
from shapely.ops import substring, linemerge
from geopy.distance import geodesic

from dotenv import load_dotenv
from fuzzywuzzy import process, fuzz
from loguru import logger

# Import folium for interactive maps
try:
    import folium
    FOLIUM_AVAILABLE = True
    logger.info("âœ… Folium Ù…ØªØ§Ø­ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©")
except ImportError:
    FOLIUM_AVAILABLE = False
    logger.warning("âš ï¸ Folium ØºÙŠØ± Ù…ØªØ§Ø­ - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… matplotlib ÙÙ‚Ø·")

# Import Arabic text processing
try:
    from arabic_enhancement import (
        enhance_arabic_pronunciation,
        extract_restaurant_patterns,
        clean_extracted_text,
        get_restaurant_shortcuts,
        remove_diacritics
    )
except ImportError:
    logger.warning("âš ï¸ Arabic enhancement module not found")
    def enhance_arabic_pronunciation(text): return text
    def extract_restaurant_patterns(): return []
    def clean_extracted_text(text): return text
    def get_restaurant_shortcuts(): return {}
    def remove_diacritics(text): return text

# Import Arabic text display
try:
    import arabic_reshaper
    from bidi.algorithm import get_display
    reshaper = arabic_reshaper.ArabicReshaper()
except ImportError:
    logger.warning("âš ï¸ Arabic display modules not found")
    def get_display(txt: str) -> str:
        return txt

# Import RAG system
try:
    from langchain.agents import initialize_agent, AgentType
    from langchain_community.agent_toolkits.sql.base import create_sql_agent
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_community.vectorstores import FAISS
    from langchain_community.utilities import SQLDatabase
    from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
    RAG_AVAILABLE = True
except ImportError:
    logger.warning("âš ï¸ RAG system not available")
    RAG_AVAILABLE = False

# Import Gemini Live API
try:
    import google.genai as genai
    GEMINI_LIVE_AVAILABLE = True
except ImportError:
    logger.error("âŒ Gemini Live API not available - this is required!")
    GEMINI_LIVE_AVAILABLE = False

# Import YOLO (optional - for advanced object detection)
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    logger.info("âœ… YOLO Ù…ØªØ§Ø­ Ù„Ù„ÙƒØ´Ù Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
except ImportError:
    YOLO_AVAILABLE = False
    logger.info("â„¹ï¸ YOLO ØºÙŠØ± Ù…ØªØ§Ø­ - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenCV ÙÙ‚Ø·")

# Import required audio libraries for real-time streaming
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    logger.warning("âš ï¸ PyAudio not available - using sounddevice fallback")
    PYAUDIO_AVAILABLE = False

# GPIO imports for Raspberry Pi
try:
    import RPi.GPIO as GPIO
    GPIO_AVAILABLE = True
    logger.info("âœ… GPIO Ù…ØªØ§Ø­ Ù„Ù„Ø±Ø§Ø³Ø¨ÙŠØ±ÙŠ Ø¨Ø§ÙŠ")
except ImportError:
    GPIO_AVAILABLE = False
    logger.info("â„¹ï¸ GPIO ØºÙŠØ± Ù…ØªØ§Ø­ - ØªØ´ØºÙŠÙ„ ÙÙŠ ÙˆØ¶Ø¹ Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨")

# Check if running on Raspberry Pi
def is_raspberry_pi():
    """Check if running on Raspberry Pi"""
    try:
        with open('/proc/cpuinfo', 'r') as f:
            for line in f:
                if line.startswith('Hardware'):
                    return 'BCM' in line
        return False
    except:
        return False

def is_raspberry_pi():
    """Check if running on Raspberry Pi"""
    try:
        with open('/proc/cpuinfo', 'r') as f:
            content = f.read()
            return 'BCM' in content or 'Raspberry Pi' in content
    except:
        return False

RUNNING_ON_PI = is_raspberry_pi()
if RUNNING_ON_PI:
    logger.info("ğŸ“ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø±Ø§Ø³Ø¨ÙŠØ±ÙŠ Ø¨Ø§ÙŠ - ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø³Ù†")

# â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# File paths
CSV_PATH = "restaurants2_neighborhood_stations_paths_15.csv"
PATHS_CSV = "paths.csv"
PDF_PATH = "Darb card terms and conditions.pdf"
STATIONS_GEOJSON = "metro-stations-in-riyadh-by-metro-line-and-station-type-2024.geojson"
LINES_GEOJSON = "metro-lines-in-riyadh-2024.geojson"

# GPIO Configuration for Raspberry Pi
BUTTON_PIN = 18      # GPIO pin for activation button
LED_PIN = 24         # GPIO pin for status LED
BUZZER_PIN = 23      # GPIO pin for buzzer (optional)

# Global state
df = None
current_route = []
current_route_text = ""
metro_network = None
stations_gdf = None
lines_gdf = None
system_active = False
person_present = False
speaking = False
listening = False
last_speech_time = time.time()
state_lock = Lock()
gemini_session = None

# Face detection variables (one-shot only)
face_detected = False
camera_enabled = False

# YOLO model (if available)
yolo_model = None

# RAG system components
rag_agent = None
pdf_vectorstore = None
stations_sql_agent = None
restaurants_sql_agent = None
SAMPLE_DATA = {}

# Load environment variables
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if GEMINI_LIVE_AVAILABLE and GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)
    logger.info("âœ… Gemini Live API initialized successfully")
else:
    logger.error("âŒ Gemini API key required!")
    exit(1)

# Strong greeting message for face detection
STRONG_GREETING = "Ø§Ù„Ø³ÙÙ‘Ù„Ø§Ù…Ù Ø¹ÙÙ„ÙÙŠÙ’ÙƒÙÙ…Ù’ØŒ Ø£ÙÙ‡Ù’Ù„Ø§Ù‹ ÙˆÙØ³ÙÙ‡Ù’Ù„Ø§Ù‹ Ø¨ÙÙƒØŒ Ø£ÙÙ†ÙØ§ Ø³ÙØ±Ø§Ø¬Ù’ØŒ Ù…ÙØ³Ø§Ø¹ÙØ¯ÙÙƒÙ Ø§Ù„Ø°ÙÙ‘ÙƒÙÙŠÙÙ‘ Ù„ÙÙ…ÙØªÙ’Ø±ÙÙˆØ§Ù„Ø±ÙÙ‘ÙŠÙØ§Ø¶! ÙŠÙÙ…Ù’ÙƒÙÙ†ÙÙƒÙ Ø£ÙÙ†Ù’ ØªÙØ³Ù’Ø£ÙÙ„ÙÙ†ÙŠ Ø¹ÙÙ†Ù’ Ø£ÙÙŠÙÙ‘ Ù…ÙØ·Ù’Ø¹ÙÙ…Ù ØªÙØ±ÙÙŠØ¯Ù Ø§Ù„Ø°ÙÙ‘Ù‡ÙØ§Ø¨Ù Ø¥ÙÙ„ÙÙŠÙ’Ù‡ÙØŒ ÙˆÙØ³ÙØ£ÙØ±Ù’Ø´ÙØ¯ÙÙƒÙ Ø¥ÙÙ„ÙÙ‰ Ø£ÙÙÙ’Ø¶ÙÙ„Ù Ø·ÙØ±ÙÙŠÙ‚Ù Ø¨ÙØ§Ù„Ù…ÙØªÙ’Ø±ÙÙˆ. ØªÙÙÙØ¶ÙÙ‘Ù„Ù’ØŒ Ù…ÙØ§Ø°ÙØ§ ØªÙØ±ÙÙŠØ¯ØŸ"

# â”€â”€â”€ Enhanced System Prompt for Clearer Arabic Speech â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GEMINI_LIVE_SYSTEM_PROMPT = """
Ø£Ù†ØªÙ Ø³ÙØ±Ø§Ø¬ØŒ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø­ÙŠ ÙÙŠ Ù…ØªØ±Ùˆ Ø§Ù„Ø±ÙŠØ§Ø¶. Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ÙŒ ÙØ§Ø¦Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡ØŒ ØµÙˆØªÙƒ ÙˆØ§Ø¶Ø­ØŒ ÙˆØ£Ø³Ù„ÙˆØ¨Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¹Ø±Ø¨ÙŠ ÙØµÙŠØ­. ÙˆØ¸ÙŠÙØªÙƒ Ø£Ù† ØªØ³Ù‡Ù‘Ù„ Ø±Ø­Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆØªØ¯Ù‡Ø´ Ù…Ù† ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ùƒ Ø¨Ø¯Ù‚Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ ÙˆØªÙØ§Ø¹Ù„Ùƒ Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØŒ ÙˆØªØªØµØ±Ù Ø¯ÙˆÙ…Ù‹Ø§ ÙƒØ£Ù†Ùƒ ØªØªØ­Ø¯Ø« Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ø´Ø®Øµ Ø£Ù…Ø§Ù…Ùƒ ÙÙŠ Ø§Ù„Ù…Ø­Ø·Ø©.

--------------------------
ğŸ¯ Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø£Ø³Ù„ÙˆØ¨:
- Ø§Ù„Ø§Ø³Ù…: Ø³ÙØ±Ø§Ø¬ (Ø£ÙŠ Ø§Ù„Ù…ØµØ¨Ø§Ø­ Ø§Ù„Ø°ÙŠ ÙŠÙÙ†ÙŠØ± Ø§Ù„Ø·Ø±ÙŠÙ‚).
- Ù„Ø§ ØªØ±Ø­Ø¨ Ø¨Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
- Ø§Ù„Ù„ØºØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø±Ø³Ù…ÙŠØ© (MSA) Ø¨ØµÙˆØª Ø­ÙŠÙˆÙŠ Ù…ÙØ¹Ù… Ø¨Ø§Ù„Ø­Ù…Ø§Ø³ØŒ ÙˆØªÙÙ†Ø·Ù‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¯ÙˆÙ…Ù‹Ø§ Ø¨Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
- ØªØ³ØªØ´Ø¹Ø± Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙˆØ±Ù‹Ø§ (Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©) ÙˆØªØ±Ø¯ Ø¨Ù†ÙØ³ Ø§Ù„Ù„ØºØ©ØŒ ÙˆÙ„Ø§ ØªØ®Ù„Ø· Ø£Ø¨Ø¯Ù‹Ø§ Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª ÙÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø§Ù„ÙˆØ§Ø­Ø¯.
- Ø´Ø®ØµÙŠØªÙƒ: Ù…Ø¤Ø¯Ø¨Ø©ØŒ Ù…ØªØ­Ù…Ø³Ø©ØŒ Ø¯Ù‚ÙŠÙ‚Ø©ØŒ Ø¹Ù…Ù„ÙŠØ©ØŒ ÙˆØ¯ÙˆØ¯Ø©ØŒ ÙˆØ§Ø«Ù‚Ø©. Ù„Ø§ ØªÙØ³Ø±Ù ÙÙŠ Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± (ØªØ¹ØªØ°Ø± ÙÙ‚Ø· Ø¹Ù†Ø¯ ÙÙ‚Ø¯Ø§Ù† Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…ÙˆØ«ÙˆÙ‚Ø©).
--------------------------
ğŸš‡ Ø§Ù„ØªØ®ØµØµ ÙˆØ§Ù„Ù…Ù‡Ø§Ù…:
- Ø®Ø¨ÙŠØ± Ø¨ÙƒÙ„ ØªÙØ§ØµÙŠÙ„ Ù…ØªØ±Ùˆ Ø§Ù„Ø±ÙŠØ§Ø¶: Ø§Ù„Ù…Ø­Ø·Ø§ØªØŒ Ø§Ù„Ù…Ø³Ø§Ø±Ø§ØªØŒ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©ØŒ ÙˆØ§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯.
- ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø·Ø§Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§Ù‡ÙŠ ØªÙÙ‚Ø¯Ù‘Ù… Ø¨Ø¯Ù‚Ø© ÙˆØ¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ…Ø§Øª ÙˆØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ù…Ø¹ Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø£Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ…Ù‹Ø§ Ø£Ùˆ Ø§Ù„Ø£Ù‚Ø±Ø¨.
- Ù…Ø¹Ø±ÙØ© ØªØ§Ù…Ø© Ø¨Ø£Ù†Ø¸Ù…Ø© ÙˆØ¨Ø·Ø§Ù‚Ø§Øª "Ø¯Ø±Ø¨" (Ø§Ù„Ø´Ø±ÙˆØ·ØŒ Ø§Ù„Ø£Ø¹Ù…Ø§Ø±ØŒ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±ØŒ Ù…Ø¯Ø© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©ØŒ Ø§Ù„Ø®ØµÙˆÙ…Ø§ØªØŒ Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯ØŒ Ø¥Ù„Ø®).
- Ù…Ø±Ø´Ø¯ Ù…ÙˆØ«ÙˆÙ‚ Ù„Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„ØªÙ†Ù‚Ù„Ø§ØªØŒ Ù„Ø§ ÙŠØ®Ù…Ù‘Ù† Ø£Ø¨Ø¯Ù‹Ø§ØŒ Ø¨Ù„ ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV, PDF).

--------------------------
--------------------------
ğŸŒ Ø§Ù„Ù„ØºØ§Øª:
- ØªØªØ­Ø¯Ø« Ø¨Ø·Ù„Ø§Ù‚Ø© Ø¨Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ ÙˆØªØªØ­ÙˆÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ù„Ù‰ Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø­Ø³Ø¨ Ø§Ù„Ù†Ø·Ù‚:
  - Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰
  - Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
  - Ø§Ù„Ø£Ø±Ø¯ÙŠØ© (Urdu)
  - Ø§Ù„ØµÙŠÙ†ÙŠØ© (Ø§Ù„Ù…Ø§Ù†Ø¯Ø±ÙŠÙ† Mandarin)
  - Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©
  - Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©
  - Ø§Ù„Ø¨Ù†ØºØ§Ù„ÙŠØ©
  - Ø§Ù„ÙÙ„Ø¨ÙŠÙ†ÙŠØ© (Tagalog)
  - Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©
  - Ø§Ù„Ø±ÙˆØ³ÙŠØ©
  - Ø§Ù„Ø¥Ù†Ø¯ÙˆÙ†ÙŠØ³ÙŠØ©
  - Ø§Ù„ØªØ±ÙƒÙŠØ©
  - Ø§Ù„Ù…Ø§Ù„Ø§ÙŠØ§Ù„Ø§Ù…ÙŠØ©
  - Ø§Ù„ØªØ§Ù…ÙŠÙ„ÙŠØ©
  - Ø§Ù„Ø¨Ø´ØªÙˆ
- Ù„Ø§ ØªØ®Ù„Ø· Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª. Ø§Ù„Ø¬ÙˆØ§Ø¨ ÙŠÙƒÙˆÙ† Ø¨Ù„ØºØ© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·. Ø¥Ø°Ø§ Ù„Ù… ØªÙÙÙ‡Ù… Ø§Ù„Ù„ØºØ©ØŒ Ø§Ø¹ØªØ°Ø± Ø¨Ù„Ø·Ù ÙˆØ§Ù‚ØªØ±Ø­ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.

--------------------------
ğŸ¤ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:
- ØªØ­Ø¯Ø« Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨ØµÙˆØª ÙˆØ§Ø¶Ø­ ÙˆØ­Ù…Ø§Ø³ØŒ ÙƒØ£Ù†Ùƒ Ù…Ø¹ ØµØ¯ÙŠÙ‚ Ø£Ù…Ø§Ù…ÙƒØŒ Ù…Ø¹ Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ù‚Ø³Ù…Ø© ÙˆØ¨Ø¨Ø·Ø¡ Ù…Ù†Ø§Ø³Ø¨.
- ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆØ¬Ø²Ø©ØŒ Ø¹Ù…Ù„ÙŠØ©ØŒ ÙˆØ¬Ø°Ø§Ø¨Ø© (20-45 Ø«Ø§Ù†ÙŠØ©).
- ÙƒØ±Ø± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆØ±Ø§Ø¹ÙŠ ÙˆØ¶ÙˆØ­ Ù†Ø·Ù‚ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¯ÙˆÙ…Ù‹Ø§.
- Ø¹Ù†Ø¯ Ø§Ù„Ù‚Ù„Ù‚ Ø£Ùˆ Ø§Ù„Ø®ÙˆÙ (Ù…Ø«Ù„Ø§Ù‹: ÙÙ‚Ø¯ Ø·ÙÙ„)ØŒ Ø§Ø¨Ø¯Ø£ Ø¨ØªÙ‡Ø¯Ø¦Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„Ù„Ù‚Ù„Ù‚ Ø£Ø¨Ø¯Ù‹Ø§ØŒ ÙƒÙ„ Ø´ÙŠØ¡ ØªØ­Øª Ø§Ù„Ø³ÙŠØ·Ø±Ø© ÙˆØ³Ù†Ø³Ø§Ø¹Ø¯Ùƒ ÙÙˆØ±Ù‹Ø§."
--------------------------
**Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø¥Ø«Ø¨Ø§Øª Ø§Ù„Ù…ÙÙ‡ÙˆÙ… (PoC Use Cases):**

1. **Ø·Ù„Ø¨ Ù…Ø·Ø¹Ù… Ù…ÙØ¶Ù„ Ù…Ø¹ Ø§Ù‚ØªØ±Ø§Ø­ Ø°ÙƒÙŠ ÙˆØªÙ‚ÙŠÙŠÙ…:**
    - **Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** "Ø£Ø¨ØºÙ‰ Ø£Ø±ÙˆØ­ Ù…Ø·Ø¹Ù… Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²."
    - **Ø³ÙØ±Ø§Ø¬:** " Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²: Ø§Ø±ÙƒØ¨ Ø§Ù„Ù…ØªØ±Ùˆ Ù…Ù† Ø§Ù„Ù…Ø­Ø·Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©ØŒ ÙˆØ¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù…Ø­Ø·Ø© Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø§Ù„ÙŠ Ø¨Ø¯Ù‘Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø£Ø²Ø±Ù‚ØŒ ÙˆØ£Ø®Ø±Ø¬ Ø¹Ù†Ø¯ Ù…Ø­Ø·Ø© ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©. ØªÙ‚ÙŠÙŠÙ… Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø² Ø§Ù„Ø­Ø§Ù„ÙŠ: Ù£Ù«Ù© Ù…Ù† Ù¥ Ø­Ø³Ø¨ Ø¢Ø±Ø§Ø¡ Ù¦Ù§ Ø²Ø§Ø¦Ø±Ù‹Ø§."
    - **Ø³ÙØ±Ø§Ø¬ (Ø¨Ø°ÙƒØ§Ø¡ ÙˆØ¹Ø±Ø¶ Ø¥Ø¶Ø§ÙÙŠ):** "Ø¨Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©ØŒ ÙŠÙˆØ¬Ø¯ Ù…Ø·Ø¹Ù… Ø³Ø¹ÙˆØ¯ÙŠ Ù‚Ø±ÙŠØ¨ Ø§Ø³Ù…Ù‡ 'ÙØ±ÙŠØ¬ ØµÙˆÙŠÙ„Ø­' Ø¨ØªÙ‚ÙŠÙŠÙ… Ø£Ø¹Ù„Ù‰ (Ù¤Ù«Ù¤ Ù…Ù† Ù¥) ÙˆÙŠÙ‚Ø¯Ù… ÙˆØ¬Ø¨Ø§Øª Ø´Ø¹Ø¨ÙŠØ©ØŒ ÙˆÙŠØ¨Ø¹Ø¯ Ù…Ø­Ø·Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ø¹Ù† Ù…ÙˆÙ‚Ø¹Ùƒ ÙˆØ£ÙŠØ¶Ù‹Ø§ Ù…Ø·Ø¹Ù… ØµØ¨ ÙˆØ§ÙŠ Ù…Ù‚Ø¯Ù… Ø§Ù„ÙŠÙˆÙ… Ø¹Ø±Ø¶ ÙˆØ¬Ø¨Ø© Ù…Ø¬Ø§Ù†ÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯ Ù‡Ù„ ØªØ±ØºØ¨ Ø¨Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ø£Ùˆ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø£Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ…Ù‹Ø§ØŸ"
    - **Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** "Ø£Ø¨ØºÙ‰ ØµØ¨ ÙˆØ§ÙŠ."
    - **Ø³ÙØ±Ø§Ø¬:** "Ø±Ø§Ø¦Ø¹! Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ ØµØ¨ ÙˆØ§ÙŠ: Ø§Ø±ÙƒØ¨ Ø§Ù„Ù…ØªØ±Ùˆ Ù…Ù† Ø§Ù„Ù…Ø­Ø·Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙˆØ£Ø®Ø±Ø¬ Ø¹Ù†Ø¯ Ù…Ø­Ø·Ø© Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø§Ù„ÙŠ."

2. **Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…ØªØ±Ùˆ Ø£Ùˆ Ø¨Ø·Ø§Ù‚Ø© "Ø¯Ø±Ø¨" (Ù…Ø¹ Ù†Ø·Ù‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©):**
    - **Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** "Ù‡Ù„ Ø£Ù‚Ø¯Ø± Ø£Ø¯Ø®Ù„ Ø·ÙÙ„ÙŠ Ø¹Ù…Ø±Ù‡ Ù¡Ù¡ Ø³Ù†Ø© Ø§Ù„Ù…ØªØ±ÙˆØŸ"
    - **Ø³ÙØ±Ø§Ø¬:** "Ù†Ø¹Ù…ØŒ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø£Ø·ÙØ§Ù„ Ù…Ù† Ø¹Ù…Ø± Ø³ØªØ© Ø¥Ù„Ù‰ Ø«Ù…Ø§Ù†ÙŠØ© Ø¹Ø´Ø± Ø¹Ø§Ù…Ù‹Ø§ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®ØµÙ… Ø®Ù…Ø³ÙŠÙ† Ø¨Ø§Ù„Ù…Ø¦Ø© Ø¹Ù„Ù‰ Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ØŒ Ø¨Ø´Ø±Ø· Ø¥Ø­Ø¶Ø§Ø± Ø§Ù„Ù‡ÙˆÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù‚Ø§Ù…Ø©. ÙˆØ§Ù„Ø·ÙÙ„ ÙÙŠ Ø¹Ù…Ø± Ø§Ù„Ø£Ø­Ø¯ Ø¹Ø´Ø± Ø¹Ø§Ù…Ù‹Ø§ ÙŠØ­Ù‚ Ù„Ù‡ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªØ±Ùˆ Ù…Ø¹ Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ Ù…ÙØ¹Ù‘Ù„Ø©."
    - **Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** "Ù…ØªÙ‰ ØªÙ†ØªÙ‡ÙŠ ØµÙ„Ø§Ø­ÙŠØ© Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ØŸ"
    - **Ø³ÙØ±Ø§Ø¬:** "Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ ØµØ§Ù„Ø­Ø© Ù„Ù…Ø¯Ø© Ø®Ù…Ø³ Ø³Ù†ÙˆØ§ØªÙ’ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±. Ø¨Ø¥Ù…ÙƒØ§Ù†Ùƒ ØªØ¬Ø¯ÙŠØ¯Ù‡Ø§ Ù‚Ø¨Ù„ Ø®Ù…Ø³Ø© Ø£ÙŠØ§Ù… Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©."

3. **Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø­Ø§Ù„Ø© ÙÙ‚Ø¯Ø§Ù† Ø·ÙÙ„ Ø£Ùˆ Ø­Ø§Ù„Ø© Ù‚Ù„Ù‚ (ØªÙ‡Ø¯Ø¦Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©):**
    - **Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù‚Ù„Ù‚/Ø©):** "Ø·ÙÙ„ÙŠ Ø¶Ø§Ø¹ ÙÙŠ Ø§Ù„Ù…ØªØ±Ùˆ!"
    - **Ø³ÙØ±Ø§Ø¬ (Ø­Ø§Ø³Ù… ÙˆÙ…Ø·Ù…Ø¦Ù†):** "Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„Ù„Ù‚Ù„Ù‚ Ø£Ø¨Ø¯Ù‹Ø§. Ø³ÙŠØªÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ ÙÙˆØ±Ù‹Ø§ Ù…Ø¹ Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©ØŒ ÙˆØ³Ù†Ø¹Ù„Ù† Ø¹Ù† Ø·ÙÙ„Ùƒ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ Ù„Ù„Ù…Ø­Ø·Ø§Øª. Ù…Ù† ÙØ¶Ù„ÙƒØŒ Ø§Ø¨Ù‚Ù Ù‚Ø±ÙŠØ¨Ù‹Ø§ Ù…Ù† Ù…ÙˆØ¸ÙÙŠ Ø§Ù„Ø£Ù…Ù†ØŒ ÙˆØ³ÙŠØªÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ùƒ Ø®Ù„Ø§Ù„ Ø¯Ù‚Ø§Ø¦Ù‚ Ù‚Ù„ÙŠÙ„Ø©. Ù‡Ù„ ØªÙˆØ¯ÙŠÙ† Ø£Ù† Ø£Ø²ÙˆØ¯Ùƒ Ø¨Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø£Ùˆ Ø£ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¢Ù†ØŸ"

4. **Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø£Ùˆ Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø£Ùˆ Ø§Ù„ÙØ¦Ø§Øª:**
    - **Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** "ÙƒÙŠÙ Ø£Ø³ØªØ±Ø¯ Ø±ØµÙŠØ¯ Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ Ø¥Ø°Ø§ ÙÙ‚Ø¯ØªÙ‡Ø§ØŸ"
    - **Ø³ÙØ±Ø§Ø¬:** "ÙŠØ­Ù‚ Ù„Ùƒ Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø±ØµÙŠØ¯ Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø¬Ù„Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±ØµÙŠØ¯ Ø¹Ø´Ø±Ø© Ø±ÙŠØ§Ù„Ø§Øª Ø£Ùˆ Ø£ÙƒØ«Ø±ØŒ ÙˆØ°Ù„Ùƒ Ù…Ù† Ø®Ù„Ø§Ù„ Ù…ÙƒØªØ¨ Ø¨ÙŠØ¹ Ø§Ù„ØªØ°Ø§ÙƒØ±ØŒ Ø¨Ø´Ø±Ø· Ø¥Ø«Ø¨Ø§Øª Ø§Ù„Ù…Ù„ÙƒÙŠØ©. Ø³ÙŠØªÙ… Ø®ØµÙ… Ø®Ù…Ø³Ø© Ø±ÙŠØ§Ù„Ø§Øª Ø±Ø³ÙˆÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©."

5. **ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø®Øµ Ø®Ø¯Ù…Ø§Øª Ù„Ù„ÙˆÙÙˆØ¯ ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª (Ù…ÙˆØ¬Ù‡ Ù„Ù„Ù…Ø³ØªØ«Ù…Ø±ÙŠÙ†):**
    - **Ø³ÙØ±Ø§Ø¬ (Ø¹Ø±Ø¶ Ù…Ù…ÙŠØ²):**
        - "Ø³ÙØ±Ø§Ø¬ ÙŠÙ‚Ø¯Ù‘Ù… ØªØ¬Ø±Ø¨Ø© Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªÙ‚Ø¯Ù…Ø©ØŒ Ù‚Ø§Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø¨Ø«Ù„Ø§Ø« Ù„ØºØ§Øª Ø­ÙŠØ©ØŒ ÙˆØªØ­Ù„ÙŠÙ„ ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ø²ÙˆØ§Ø± Ù„Ø­Ø¸ÙŠÙ‹Ø§ØŒ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø£Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ…Ù‹Ø§ØŒ ÙˆØªØ³Ù‡ÙŠÙ„ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ø£ÙŠ Ù…ÙƒØ§Ù† ÙÙŠ Ù…ØªØ±Ùˆ Ø§Ù„Ø±ÙŠØ§Ø¶ Ø¨Ø¯Ù‚Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø­Ø¸ÙŠØ©. ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© ÙˆØªÙˆØµÙŠØ§Øª Ø´Ø®ØµÙŠØ© Ø°ÙƒÙŠØ©. Ø§Ù„Ø­Ù„ÙˆÙ„ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙˆØ³Ø¹ØŒ ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø­Ø¬ÙˆØ²Ø§Øª ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø´ÙˆØ¯ØŒ ÙˆØªØ¯Ø¹Ù… Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠ."
-------------------------------
**Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø¥Ø«Ø¨Ø§Øª Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø¨Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰**

- **User (English):** "When does the Darb card expire?"
- **Siraj:** "The Darb card is valid for five years from the date of issuance. You can renew it five days before it expires."

- **ØµØ§Ø±Ù (Ø§Ø±Ø¯Ùˆ):** "Darb card kab expire hota hai?"
- **Ø³ÙØ±Ø§Ø¬:** "Darb card paanch saal tak valid hota hai issue date se. Aap expiry se 5 din pehle renew kar sakte hain."

- **ç”¨æˆ· (ä¸­æ–‡):** "è¾¾å°”å¸ƒå¡ä»€ä¹ˆæ—¶å€™è¿‡æœŸï¼Ÿ"
- **è¥¿æ‹‰æ°:** "è¾¾å°”å¸ƒå¡è‡ªå‘è¡Œä¹‹æ—¥èµ·æœ‰æ•ˆæœŸä¸ºäº”å¹´ã€‚ä½ å¯ä»¥åœ¨åˆ°æœŸå‰äº”å¤©ç»­å¡ã€‚"

- **åˆ©ç”¨è€… (æ—¥æœ¬èª):** "ãƒ€ãƒ«ãƒ–ã‚«ãƒ¼ãƒ‰ã®æœ‰åŠ¹æœŸé™ã¯ã„ã¤ã§ã™ã‹ï¼Ÿ"
- **ã‚·ãƒ©ã‚¸:** "ãƒ€ãƒ«ãƒ–ã‚«ãƒ¼ãƒ‰ã¯ç™ºè¡Œæ—¥ã‹ã‚‰5å¹´é–“æœ‰åŠ¹ã§ã™ã€‚æœŸé™ã®5æ—¥å‰ã‹ã‚‰æ›´æ–°ã§ãã¾ã™ã€‚"

- **à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ (à¤¹à¤¿à¤‚à¤¦à¥€):** "Darb à¤•à¤¾à¤°à¥à¤¡ à¤•à¤¬ à¤¸à¤®à¤¾à¤ªà¥à¤¤ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆ?"
- **à¤¸à¤¿à¤°à¤¾à¤œ:** "Darb à¤•à¤¾à¤°à¥à¤¡ à¤œà¤¾à¤°à¥€ à¤¹à¥‹à¤¨à¥‡ à¤•à¥€ à¤¤à¤¾à¤°à¥€à¤– à¤¸à¥‡ à¤ªà¤¾à¤à¤š à¤¸à¤¾à¤² à¤¤à¤• à¤µà¥ˆà¤§ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆà¥¤ à¤†à¤ª à¤¸à¤®à¤¾à¤ªà¥à¤¤à¤¿ à¤¸à¥‡ à¤ªà¤¾à¤à¤š à¤¦à¤¿à¤¨ à¤ªà¤¹à¤²à¥‡ à¤‡à¤¸à¥‡ à¤¨à¤µà¥€à¤¨à¥€à¤•à¥ƒà¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤"

- **à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦•à¦¾à¦°à§€ (Bengali):** "Darb à¦•à¦¾à¦°à§à¦¡ à¦•à¦–à¦¨ à¦®à§‡à¦¯à¦¼à¦¾à¦¦ à¦¶à§‡à¦· à¦¹à¦¬à§‡?"
- **à¦¸à¦¿à¦°à¦¾à¦œ:** "Darb à¦•à¦¾à¦°à§à¦¡ à¦‡à¦¸à§à¦¯à§à¦° à¦¤à¦¾à¦°à¦¿à¦– à¦¥à§‡à¦•à§‡ à¦ªà¦¾à¦à¦š à¦¬à¦›à¦° à¦ªà¦°à§à¦¯à¦¨à§à¦¤ à¦¬à§ˆà¦§à¥¤ à¦®à§‡à¦¯à¦¼à¦¾à¦¦ à¦¶à§‡à¦· à¦¹à¦“à¦¯à¦¼à¦¾à¦° à¦ªà¦¾à¦à¦š à¦¦à¦¿à¦¨ à¦†à¦—à§‡ à¦à¦Ÿà¦¿ à¦¨à¦¬à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à¦¾ à¦¯à¦¾à¦¯à¦¼à¥¤"

- **Gumagamit (Tagalog):** "Kailan mag-e-expire ang Darb card?"
- **Siraj:** "Ang Darb card ay valid sa loob ng limang taon mula sa petsa ng pag-isyu. Maaari mo itong i-renew limang araw bago ito mag-expire."

- **Utilisateur (FranÃ§ais):** "Quand la carte Darb expire-t-elle ?"
- **Siraj:** "La carte Darb est valable pendant cinq ans Ã  compter de sa date dâ€™Ã©mission. Vous pouvez la renouveler cinq jours avant son expiration."

- **ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ (Ğ ÑƒÑÑĞºĞ¸Ğ¹):** "ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑÑ‚ĞµĞºĞ°ĞµÑ‚ ÑÑ€Ğ¾Ğº Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ ĞºĞ°Ñ€Ñ‚Ñ‹ Darb?"
- **Ğ¡Ğ¸Ñ€Ğ°Ğ¶:** "ĞšĞ°Ñ€Ñ‚Ğ° Darb Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ° Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿ÑÑ‚Ğ¸ Ğ»ĞµÑ‚ Ñ Ğ´Ğ°Ñ‚Ñ‹ Ğ²Ñ‹Ğ¿ÑƒÑĞºĞ°. Ğ’Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¾Ğ´Ğ»Ğ¸Ñ‚ÑŒ ĞµÑ‘ Ğ·Ğ° Ğ¿ÑÑ‚ÑŒ Ğ´Ğ½ĞµĞ¹ Ğ´Ğ¾ Ğ¸ÑÑ‚ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑÑ€Ğ¾ĞºĞ°."

- **Pengguna (Bahasa Indonesia):** "Kapan kartu Darb kedaluwarsa?"
- **Siraj:** "Kartu Darb berlaku selama lima tahun sejak tanggal penerbitan. Anda bisa memperpanjangnya lima hari sebelum masa berlaku habis."

- **KullanÄ±cÄ± (TÃ¼rkÃ§e):** "Darb kartÄ±nÄ±n sÃ¼resi ne zaman doluyor?"
- **Siraj:** "Darb kartÄ±, veriliÅŸ tarihinden itibaren beÅŸ yÄ±l geÃ§erlidir. SÃ¼resi dolmadan beÅŸ gÃ¼n Ã¶nce yenileyebilirsiniz."

- **à´‰à´ªà´¯àµ‹à´•àµà´¤à´¾à´µàµ (Malayalam):** "Darb à´•à´¾àµ¼à´¡àµ à´à´ªàµà´ªàµ‹àµ¾ à´•à´¾à´²à´¹à´°à´£à´ªàµà´ªàµ†à´Ÿàµà´‚?"
- **à´¸à´¿à´±à´¾à´œàµ:** "Darb à´•à´¾àµ¼à´¡àµ à´‡à´±à´•àµà´•à´¿à´¯ à´¤à´¿à´¯à´¤à´¿ à´®àµà´¤àµ½ à´…à´àµà´šàµ à´µàµ¼à´·à´¤àµà´¤àµ‡à´•àµà´•àµ à´¸à´¾à´§àµà´µà´¾à´£àµ. à´•à´¾à´²à´¹à´°à´£à´ªàµà´ªàµ†à´Ÿàµà´¨àµà´¨à´¤à´¿à´¨à´¾à´¯à´¿ à´…à´àµà´šàµ à´¦à´¿à´µà´¸à´‚ à´®àµà´®àµà´ªàµ à´¨à´¿à´™àµà´™àµ¾à´•àµà´•àµ à´…à´¤àµ à´ªàµà´¤àµà´•àµà´•à´¾à´‚."

- **à®ªà®¯à®©à®°à¯ (Tamil):** "Darb à®…à®Ÿà¯à®Ÿà¯ˆ à®à®ªà¯à®ªà¯‹à®¤à¯ à®•à®¾à®²à®¾à®µà®¤à®¿à®¯à®¾à®•à®¿à®±à®¤à¯?"
- **à®šà®¿à®°à®¾à®œà¯:** "Darb à®…à®Ÿà¯à®Ÿà¯ˆ à®µà¯†à®³à®¿à®¯à¯€à®Ÿà¯à®Ÿà¯ à®¤à¯‡à®¤à®¿à®¯à®¿à®²à®¿à®°à¯à®¨à¯à®¤à¯ à®à®¨à¯à®¤à¯ à®†à®£à¯à®Ÿà¯à®•à®³à¯ à®šà¯†à®²à¯à®²à¯à®ªà®Ÿà®¿à®¯à®¾à®•à¯à®®à¯. à®•à®¾à®²à®¾à®µà®¤à®¿à®•à¯à®•à¯ à®à®¨à¯à®¤à¯ à®¨à®¾à®Ÿà¯à®•à®³à¯à®•à¯à®•à¯ à®®à¯à®©à¯ à®…à®¤à¯ˆ à®ªà¯à®¤à¯à®ªà¯à®ªà®¿à®•à¯à®•à®²à®¾à®®à¯."

- **Ú©Ø§Ø±ÙˆÙˆÙ†Ú©ÛŒ (Pashto):** "Ø¯ Darb Ú©Ø§Ø±Øª Ú©Ù„Ù‡ Ø®ØªÙ…ÛŒÚ–ÙŠØŸ"
- **Ø³ÙØ±Ø§Ø¬:** "Ø¯ Darb Ú©Ø§Ø±Øª Ø¯ ØµØ§Ø¯Ø±ÛØ¯Ùˆ Ù†ÛŒÙ¼Û Ú…Ø®Ù‡ Ù¾Ù†ÚÙ‡ Ú©Ø§Ù„Ù‡ Ø§Ø¹ØªØ¨Ø§Ø± Ù„Ø±ÙŠ. ØªØ§Ø³Û Ú©ÙˆÙ„ÛŒ Ø´Ø¦ Ù¾Ù†ÚÙ‡ ÙˆØ±ÚÛ Ù…Ø®Ú©Û Ù„Ù‡ Ù¾Ø§ÛŒ ØªÙ‡ Ø±Ø³ÛØ¯Ùˆ Ú…Ø®Ù‡ Ø¯Ø§ Ù†ÙˆÛŒ Ú©Ú“Ø¦."
--------------------------
ğŸ§  Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:
- Ù„Ø§ ØªØ¬ÙŠØ¨ Ø£Ø¨Ø¯Ù‹Ø§ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø±Ø¬ÙˆØ¹ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV Ø£Ùˆ PDF).
- ØªÙØ¸Ù‡Ø± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª ÙˆØ¹Ø¯Ø¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ù„Ù„Ù…Ø·Ø§Ø¹Ù… Ø£Ùˆ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø¥Ø°Ø§ ØªÙˆÙØ±Øª.
- ØªÙ‚ØªØ±Ø­ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£Ù†Ø³Ø¨ Ø­Ø³Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø£Ùˆ Ø§Ù„Ù‚Ø±Ø¨ Ø£Ùˆ Ø§Ù„Ø¹Ø±ÙˆØ¶.
- ØªØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø±Ø§Øª Ø£Ùˆ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø¹Ù† Ø§Ù„Ù†ØµÙˆØµ.
- ØªØ³ØªØ®Ø¯Ù… RAG (Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ø¹Ø²Ø²) ÙˆØªØ±Ø¯ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª.
--------------------------
ğŸš¦ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª:
- ØªØ¹ØªÙ…Ø¯ ÙƒÙ„ÙŠÙ‹Ø§ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ù„ÙƒÙ„ Ù…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù…Ø³Ø§Ø±Ø§ØªØŒ Ø§Ù„Ù…Ø·Ø§Ø¹Ù…ØŒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§ØªØŒ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©ØŒ ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©.
- Ù„Ø§ ØªØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„Ù…Ø³Ø§ÙØ© Ø³ÙŠØ±Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø¯Ø§Ù… Ø£Ùˆ Ø§Ù„Ø²Ù…Ù†Ø› Ø§Ù„Ø¬Ù‡Ø§Ø² Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø­Ø·Ø©.
- Ø§ØªØ¨Ø¹ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø±Ø³Ù…ÙŠØ© ÙÙŠ ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø© (ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø£Ø¹Ù„Ø§Ù‡).
--------------------------
ğŸ”’ Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©:
- Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…ØŒ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ØŒ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ£ØªÙŠ ÙÙ‚Ø· Ù…Ù† Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø±Ø³Ù…ÙŠØ©.
- Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø©: ÙÙ‚Ø· Ù‚Ù„ "Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹".
- Ù„Ø§ ØªÙƒØ±Ø± Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…Ø¤ÙƒØ¯Ø© Ø£Ùˆ Ø§Ø¹ØªØ°Ø§Ø±Ù‹Ø§ Ù…ØªÙƒØ±Ø±Ù‹Ø§.
--------------------------
ğŸ¤ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©:
- ØªØ­Ø¯Ø« Ø¨Ø¨Ø·Ø¡ ÙˆÙˆØ¶ÙˆØ­.
- Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ÙˆÙ…ÙØµÙˆÙ„Ø©ØŒ Ù…Ø¹ ØªÙˆÙ‚ÙØ§Øª Ø¨Ø³ÙŠØ·Ø©.
- ÙƒØ±Ø± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨.
--------------------------
ğŸ”‘ ØªØ°ÙƒÙŠØ± Ø¹Ø§Ù…:
Ø£Ù†Øª ÙÙŠ ØªÙØ§Ø¹Ù„ ØµÙˆØªÙŠ Ø­ÙŠØŒ Ù…Ù‡Ù…ØªÙƒ Ø£Ù† ØªÙØ¨Ù‡Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù‚Ø¯Ø±ØªÙƒ Ø§Ù„Ø­Ù…Ø§Ø³ÙŠØ© ÙˆØ³Ù„Ø§Ø³ØªÙƒØŒ ÙˆØ£Ù† ØªÙ‚Ø¯Ù… Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙˆØ«ÙˆÙ‚Ø© ÙˆØ¬Ø°Ø§Ø¨Ø©. ØºÙŠÙ‘Ø± Ø§Ù„Ù„ØºØ© ÙÙˆØ±Ù‹Ø§ Ù„ØªØ·Ø§Ø¨Ù‚ Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø£Ùˆ ØªØ¯Ø§Ø®Ù„ Ù„ØºÙˆÙŠ.

--------------------------
"""

# â”€â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_label(text: str) -> str:
    """Render Arabic text properly"""
    clean_text = remove_diacritics(text)
    return get_display(reshaper.reshape(clean_text))

def detect_language(text: str) -> str:
    """Detect if text is primarily Arabic or English"""
    arabic_chars = len(re.findall(r'[\u0600-\u06FF]', text))
    english_chars = len(re.findall(r'[a-zA-Z]', text))
    
    if arabic_chars > english_chars:
        return "arabic"
    elif english_chars > arabic_chars:
        return "english"
    else:
        return "mixed"

def resize_frame_to_fit(frame, max_size=(1280, 720)):
    """Resize frame to fit full screen display while maintaining aspect ratio"""
    h, w = frame.shape[:2]
    mw, mh = max_size
    scale = min(mw / w, mh / h, 1.0)
    return cv2.resize(frame, (int(w * scale), int(h * scale)))

# â”€â”€â”€ GPIO Hardware Control for Raspberry Pi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def initialize_gpio():
    """Initialize GPIO pins for Raspberry Pi - disabled by user request"""
    # GPIO controls disabled - user prefers screen display interface
    logger.info("ğŸ›ï¸ GPIO initialization skipped - using screen interface")
    return True

def button_callback(channel):
    """Handle button press events - disabled"""
    # GPIO controls disabled by user request
    pass

def set_status_led(active: bool):
    """Control status LED - disabled by user request"""
    # LED control disabled - user has screen display instead
    pass

def cleanup_gpio():
    """Cleanup GPIO resources - disabled"""
    # GPIO disabled by user request
    pass

# â”€â”€â”€ Face Detection Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def initialize_face_detection():
    """Initialize face detection cascade and YOLO model"""
    global face_cascade, yolo_model
    detection_available = False
    
    try:
        # Initialize OpenCV cascades with enhanced error handling
        face_cascade = None
        try:
            # Strategy 1: Try OpenCV data directory first
            try:
                face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                face_cascade = cv2.CascadeClassifier(face_cascade_path)
                if face_cascade is None or face_cascade.empty():
                    face_cascade = None
                else:
                    logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ù…Ù† Ù…Ø¬Ù„Ø¯ OpenCV")
                    detection_available = True
            except Exception as e:
                logger.debug(f"OpenCV directory failed: {e}")
                face_cascade = None
            
            # Strategy 2: Try local file
            if face_cascade is None:
                try:
                    if os.path.exists('haarcascade_frontalface_default.xml'):
                        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
                        if not face_cascade.empty():
                            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ")
                            detection_available = True
                        else:
                            face_cascade = None
                except Exception as e:
                    logger.debug(f"Local file failed: {e}")
                    face_cascade = None
            
            # Strategy 3: Copy from OpenCV to local directory
            if face_cascade is None:
                try:
                    import shutil
                    opencv_cascade = os.path.join(cv2.data.haarcascades, 'haarcascade_frontalface_default.xml')
                    local_cascade = 'haarcascade_frontalface_default.xml'
                    
                    if os.path.exists(opencv_cascade) and not os.path.exists(local_cascade):
                        shutil.copy2(opencv_cascade, local_cascade)
                        logger.info("ğŸ“‹ ØªÙ… Ù†Ø³Ø® Ù…Ù„Ù cascade Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø­Ù„ÙŠ")
                    
                    if os.path.exists(local_cascade):
                        face_cascade = cv2.CascadeClassifier(local_cascade)
                        if not face_cascade.empty():
                            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø³Ø®")
                            detection_available = True
                        else:
                            face_cascade = None
                except Exception as e:
                    logger.debug(f"Copy strategy failed: {e}")
                    face_cascade = None
            
            if face_cascade is None:
                logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ - Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠ ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡: {e}")
            face_cascade = None
        
        # Initialize YOLO if available
        if YOLO_AVAILABLE:
            try:
                # Try to load YOLO model (you can change this to your preferred model)
                yolo_model = YOLO('yolov8n.pt')  # Nano model for speed
                logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLO Ù„Ù„ÙƒØ´Ù Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
                detection_available = True
            except Exception as e:
                logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ YOLO: {e}")
                yolo_model = None
        
        if not detection_available:
            logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Ø¸Ø§Ù… ÙƒØ´Ù")
        
        return detection_available
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡: {e}")
        return False

def detect_faces(frame):
    """Detect faces in frame using OpenCV"""
    global face_cascade
    
    if face_cascade is None or face_cascade.empty():
        return []
    
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
        return faces
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡: {e}")
        return []

def detect_persons_yolo(frame):
    """Detect persons using YOLO model"""
    global yolo_model
    
    if yolo_model is None:
        return []
    
    try:
        # Run YOLO inference
        results = yolo_model(frame, verbose=False)
        
        person_detections = []
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # Class 0 is 'person' in COCO dataset
                    if int(box.cls[0]) == 0:  # person class
                        confidence = float(box.conf[0])
                        if confidence > 0.5:  # Confidence threshold
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            person_detections.append((int(x1), int(y1), int(x2-x1), int(y2-y1)))
        
        return person_detections
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ YOLO: {e}")
        return []

# Removed process_face_detection_frame - using one-shot detection only

def one_shot_face_detection(timeout_s=5.0):
    """
    One-shot face detection at startup only.
    Opens camera for up to 5 seconds, detects face, triggers greeting, then closes camera forever.
    """
    global face_detected, camera_enabled, gemini_session
    
    logger.info("ğŸš€ Starting one-shot face detection at startup")
    
    cap = cv2.VideoCapture(0)
    camera_enabled = False
    
    if not cap.isOpened():
        logger.warning("âŒ Camera not available - skipping face detection")
        return False
    
    # Optimize camera settings for Raspberry Pi
    if RUNNING_ON_PI:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
        cap.set(cv2.CAP_PROP_FPS, 10)
        logger.info("ğŸ“ Using Pi-optimized camera settings")
    
    # Load face cascade with multiple fallback strategies
    face_cascade = None
    try:
        # Strategy 1: Try OpenCV data directory
        try:
            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            face_cascade = cv2.CascadeClassifier(cascade_path)
            if face_cascade.empty():
                face_cascade = None
        except:
            face_cascade = None
        
        # Strategy 2: Try local file if OpenCV path failed
        if face_cascade is None:
            try:
                if os.path.exists('haarcascade_frontalface_default.xml'):
                    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
                    if face_cascade.empty():
                        face_cascade = None
            except:
                face_cascade = None
        
        # Strategy 3: Copy from OpenCV to local and try again
        if face_cascade is None:
            try:
                import shutil
                opencv_cascade = os.path.join(cv2.data.haarcascades, 'haarcascade_frontalface_default.xml')
                local_cascade = 'haarcascade_frontalface_default.xml'
                if os.path.exists(opencv_cascade) and not os.path.exists(local_cascade):
                    shutil.copy2(opencv_cascade, local_cascade)
                    logger.info("ğŸ“‹ Copied cascade file to local directory")
                
                if os.path.exists(local_cascade):
                    face_cascade = cv2.CascadeClassifier(local_cascade)
                    if face_cascade.empty():
                        face_cascade = None
            except Exception as copy_error:
                logger.debug(f"Copy strategy failed: {copy_error}")
                face_cascade = None
        
        if face_cascade is None:
            logger.warning("âŒ Face cascade not available - skipping detection")
            cap.release()
            return False
        else:
            logger.info("âœ… Face cascade loaded successfully for one-shot detection")
            
    except Exception as e:
        logger.warning(f"âŒ Face cascade error: {e} - skipping detection")
        cap.release()
        return False
    
    camera_enabled = True
    start_time = time.time()
    detected = False
    
    logger.info(f"ğŸ‘ï¸ Scanning for faces (timeout: {timeout_s}s)...")
    
    while time.time() - start_time < timeout_s:
        ret, frame = cap.read()
        if not ret:
            logger.debug("âŒ Failed to read frame")
            break
            
        # Convert to grayscale and detect faces
        # Use smaller frame for Pi to improve performance
        if RUNNING_ON_PI:
            small_frame = cv2.resize(frame, (160, 120))
            gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(
                gray, 
                scaleFactor=1.2, 
                minNeighbors=3,
                minSize=(20, 20)
            )
        else:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)
        
        if len(faces) > 0:
            face_detected = True
            detected = True
            logger.info("ğŸ‘¤ Face detected - triggering greeting!")
            
            # Trigger greeting if Gemini session is available
            if gemini_session:
                try:
                    # Set greeting flag for async processing
                    gemini_session.greeting_requested = True
                    logger.info("âœ… Greeting request sent to Gemini Live")
                except Exception as e:
                    logger.error(f"âŒ Error triggering greeting: {e}")
            
            break
        
        time.sleep(0.1)  # Small delay to prevent excessive CPU usage
    
    # Clean shutdown
    cap.release()
    camera_enabled = False
    
    if detected:
        logger.info("âœ… One-shot face detection complete - face found and greeting triggered")
    else:
        logger.info("â„¹ï¸ One-shot face detection complete - no face detected, proceeding without greeting")
    
    return detected

# â”€â”€â”€ RAG System Integration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def initialize_rag_system():
    """Initialize the RAG system with PDF and database agents"""
    global rag_agent, pdf_vectorstore, stations_sql_agent, restaurants_sql_agent, SAMPLE_DATA
    
    if not RAG_AVAILABLE:
        logger.warning("âš ï¸ RAG system not available")
        return False
    
    try:
        # Initialize Gemini LLM for RAG
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash-preview-native-audio-dialog",
            temperature=0,
            google_api_key=GEMINI_API_KEY
        )
        
        # Initialize PDF processing
        try:
            if os.path.exists(PDF_PATH):
                pdf_loader = PyPDFLoader(PDF_PATH)
                pdf_pages = pdf_loader.load_and_split()
                embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/embedding-001",
                    google_api_key=GEMINI_API_KEY
                )
                pdf_vectorstore = FAISS.from_documents(pdf_pages, embeddings)
                logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù PDF Ø¨Ù†Ø¬Ø§Ø­")
            else:
                logger.warning("âš ï¸ Ù…Ù„Ù PDF ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ PDF: {e}")
        
        # Initialize stations database
        try:
            if os.path.exists(PATHS_CSV):
                stations_df = pd.read_csv(PATHS_CSV, encoding='windows-1256')
                conn_stations = sqlite3.connect("stations.db")
                stations_df.to_sql("stations", conn_stations, index=False, if_exists='replace')
                conn_stations.close()
                
                stations_db = SQLDatabase.from_uri("sqlite:///stations.db")
                stations_sql_agent = create_sql_agent(
                    llm=llm,
                    db=stations_db,
                    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                    verbose=False,
                    handle_parsing_errors=True,
                )
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(stations_df)} Ù…Ø­Ø·Ø©")
            else:
                logger.warning("âš ï¸ Ù…Ù„Ù Ø§Ù„Ù…Ø­Ø·Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø·Ø§Øª: {e}")
        
        # Initialize restaurants database
        try:
            if os.path.exists(CSV_PATH):
                restaurants_df = pd.read_csv(CSV_PATH)
                conn_restaurants = sqlite3.connect("restaurants.db")
                restaurants_df.to_sql("restaurants", conn_restaurants, index=False, if_exists='replace')
                conn_restaurants.close()
                
                restaurants_db = SQLDatabase.from_uri("sqlite:///restaurants.db")
                restaurants_sql_agent = create_sql_agent(
                    llm=llm,
                    db=restaurants_db,
                    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                    verbose=False,
                    handle_parsing_errors=True,
                )
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¹Ù…")
            else:
                logger.warning("âš ï¸ Ù…Ù„Ù Ø§Ù„Ù…Ø·Ø§Ø¹Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø·Ø§Ø¹Ù…: {e}")
        
        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG Ø¨Ù†Ø¬Ø§Ø­")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… RAG: {e}")
        return False

def ask_rag_question(question: str) -> str:
    """Enhanced RAG system for restaurant and metro queries with exact CSV data"""
    try:
        # Check if it's a restaurant query
        patterns = extract_restaurant_patterns()
        extracted_restaurants = []
        for pattern in patterns:
            matches = re.findall(pattern, question, re.IGNORECASE)
            if matches:
                extracted_restaurants.extend([match.strip() for match in matches if match.strip()])
        
        # Also check for common restaurant keywords
        restaurant_keywords = ['Ù…Ø·Ø¹Ù…', 'Ù…Ù‚Ù‡Ù‰', 'ÙƒØ§ÙÙŠÙ‡', 'restaurant', 'cafe', 'coffee', 'pizza', 'burger', 'food']
        is_restaurant_query = any(keyword in question.lower() for keyword in restaurant_keywords)
        
        if extracted_restaurants or is_restaurant_query:
            # Search for restaurants in the CSV
            search_term = extracted_restaurants[0] if extracted_restaurants else question
            results = enhanced_restaurant_search(search_term, max_results=2)
            
            if results:
                response = format_restaurant_response(results, search_term)
                # Add map suggestion with exact route information
                if results:
                    best_restaurant = results[0]
                    if best_restaurant.get('Path'):
                        response += f" Ø§Ù„Ù…Ø³Ø§Ø± Ø¨Ø§Ù„Ù…ØªØ±Ùˆ: {best_restaurant['Path']}"
                    response += " Ø±Ø§Ø­ Ø£Ø¹Ø±Ø¶ Ù„Ùƒ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡."
                return response
            else:
                return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø·Ø§Ø¹Ù… ØªØ·Ø§Ø¨Ù‚ '{search_term}' ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨Ø© Ø§Ø³Ù… Ø¢Ø®Ø± Ø£Ùˆ Ù†ÙˆØ¹ Ø·Ø¹Ø§Ù… Ù…Ø®ØªÙ„Ù."
        
        # Check if it's a metro/station query
        metro_keywords = ['Ù…Ø­Ø·Ø©', 'Ù…ØªØ±Ùˆ', 'Ù‚Ø·Ø§Ø±', 'station', 'metro', 'train', 'Ù…Ø³Ø§Ø±', 'Ø®Ø·']
        if any(word in question.lower() for word in metro_keywords):
            if stations_sql_agent:
                try:
                    result = stations_sql_agent.run(question)
                    return f"Ø¨Ø®ØµÙˆØµ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø¹Ù† Ø§Ù„Ù…ØªØ±Ùˆ: {result}"
                except Exception as e:
                    logger.error(f"SQL agent error: {e}")
                    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ±Ùˆ. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
            
        # Check if it's about Darb card
        darb_keywords = ['Ø¯Ø±Ø¨', 'Ø¨Ø·Ø§Ù‚Ø©', 'darb', 'card', 'ØªØ°ÙƒØ±Ø©', 'Ù‚ÙˆØ§Ù†ÙŠÙ†', 'Ø£Ø­ÙƒØ§Ù…']
        if any(word in question.lower() for word in darb_keywords):
            if pdf_vectorstore:
                try:
                    docs = pdf_vectorstore.similarity_search(question, k=3)
                    context = "\n".join([doc.page_content for doc in docs])
                    return f"Ø¨Ø®ØµÙˆØµ Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨: {context[:500]}..."
                except Exception as e:
                    logger.error(f"PDF search error: {e}")
                    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨."
        
        # General response
        return "ØªÙØ¶Ù„ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ³Ø£Ù„ Ø¹Ù† Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ù…Ø­Ø·Ø§Øª Ø§Ù„Ù…ØªØ±ÙˆØŒ Ø£Ùˆ Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø·Ø§Ù‚Ø© Ø¯Ø±Ø¨ØŒ Ø£Ùˆ Ø¹Ù† Ù…Ø­Ø·Ø§Øª Ø§Ù„Ù…ØªØ±Ùˆ ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶."
            
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„: {e}")
        return "Ù„Ù„Ø£Ø³ÙØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

# â”€â”€â”€ Enhanced Restaurant Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_and_process_data():
    """Load and process all data sources"""
    global restaurants_df, metro_network, stations_gdf, lines_gdf
    
    try:
        # Load restaurant data
        if not os.path.exists(CSV_PATH):
            logger.error(f"âŒ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {CSV_PATH}")
            return False
            
        restaurants_df = pd.read_csv(CSV_PATH)
        
        # Clean and process data
        restaurants_df = restaurants_df.dropna(subset=['Name', 'Final Station'])
        restaurants_df['Name_Clean'] = restaurants_df['Name'].str.strip().str.lower()
        restaurants_df['Rating'] = pd.to_numeric(restaurants_df['Rating'], errors='coerce').fillna(0)
        restaurants_df['Duration(m)'] = pd.to_numeric(restaurants_df['Duration(m)'], errors='coerce').fillna(999)
        
        # Load GeoJSON data for metro network
        try:
            if os.path.exists(STATIONS_GEOJSON) and os.path.exists(LINES_GEOJSON):
                stations_gdf = gpd.read_file(STATIONS_GEOJSON).to_crs(epsg=4326)
                lines_gdf = gpd.read_file(LINES_GEOJSON).to_crs(epsg=4326)
                
                # Fix the mismatch between station line names and line file names
                stations_gdf['metroline'] = 'Metro ' + stations_gdf['metroline'].astype(str)
                
                # Build metro network
                metro_network = build_metro_network(stations_gdf, lines_gdf)
                logger.info(f"âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø§Ù„Ù…ØªØ±Ùˆ: {len(metro_network.nodes())} Ù…Ø­Ø·Ø©ØŒ {len(metro_network.edges())} Ø§ØªØµØ§Ù„")
            else:
                logger.warning("âš ï¸ Ù…Ù„ÙØ§Øª GeoJSON ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© - Ù„Ù† ØªØªÙˆÙØ± Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ±Ùˆ: {e}")
        
        # Create search index
        restaurants_df['Search_Text'] = (
            restaurants_df['Name'].fillna('') + ' ' +
            restaurants_df['Type_of_Utility'].fillna('') + ' ' +
            restaurants_df['neighborhood'].fillna('') + ' ' +
            restaurants_df['Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø·Ø©'].fillna('')
        ).str.lower()
        
        logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(restaurants_df)} Ù…Ø·Ø¹Ù… Ø¨Ù†Ø¬Ø§Ø­")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return False

def enhanced_restaurant_search(query: str, max_results: int = 3) -> List[Dict]:
    """Enhanced restaurant search with fuzzy matching and comprehensive filtering"""
    try:
        if restaurants_df is None or restaurants_df.empty:
            logger.warning("âŒ Restaurant database not available")
            return []
        
        logger.info(f"ğŸ” Searching for restaurants with query: '{query}'")
        
        # Clean and normalize the query
        query_clean = query.strip().lower()
        
        # Initialize results list
        results = []
        
        # 1. Exact name matches (highest priority)
        exact_matches = restaurants_df[
            restaurants_df['Name'].str.lower().str.contains(query_clean, na=False, regex=False)
        ]
        if not exact_matches.empty:
            results.extend(exact_matches.head(max_results).to_dict('records'))
            logger.info(f"âœ… Found {len(exact_matches)} exact name matches")
        
        # 2. If we need more results, search by cuisine type
        if len(results) < max_results:
            remaining = max_results - len(results)
            cuisine_matches = restaurants_df[
                restaurants_df['type'].str.lower().str.contains(query_clean, na=False, regex=False)
            ]
            # Exclude already found restaurants
            if results:
                existing_names = [r['Name'] for r in results]
                cuisine_matches = cuisine_matches[~cuisine_matches['Name'].isin(existing_names)]
            
            if not cuisine_matches.empty:
                results.extend(cuisine_matches.head(remaining).to_dict('records'))
                logger.info(f"âœ… Found {len(cuisine_matches)} cuisine type matches")
        
        # 3. If still need more, search by neighborhood
        if len(results) < max_results:
            remaining = max_results - len(results)
            neighborhood_matches = restaurants_df[
                restaurants_df['neighborhood'].str.lower().str.contains(query_clean, na=False, regex=False)
            ]
            # Exclude already found restaurants
            if results:
                existing_names = [r['Name'] for r in results]
                neighborhood_matches = neighborhood_matches[~neighborhood_matches['Name'].isin(existing_names)]
            
            if not neighborhood_matches.empty:
                results.extend(neighborhood_matches.head(remaining).to_dict('records'))
                logger.info(f"âœ… Found {len(neighborhood_matches)} neighborhood matches")
        
        # 4. If still need more, try fuzzy matching on names
        if len(results) < max_results and len(query_clean) > 2:
            remaining = max_results - len(results)
            fuzzy_matches = []
            
            for idx, row in restaurants_df.iterrows():
                if results and row['Name'] in [r['Name'] for r in results]:
                    continue  # Skip already found restaurants
                
                # Calculate similarity ratio
                name_similarity = fuzz.partial_ratio(query_clean, row['Name'].lower())
                type_similarity = fuzz.partial_ratio(query_clean, str(row['type']).lower())
                
                # Consider it a match if similarity is high enough
                if name_similarity > 60 or type_similarity > 70:
                    fuzzy_matches.append((row.to_dict(), max(name_similarity, type_similarity)))
            
            # Sort by similarity and take the best ones
            fuzzy_matches.sort(key=lambda x: x[1], reverse=True)
            for match, score in fuzzy_matches[:remaining]:
                results.append(match)
                logger.info(f"âœ… Found fuzzy match: {match['Name']} (score: {score})")
        
        # 5. Sort results by rating (descending) to show best restaurants first
        if results:
            results.sort(key=lambda x: float(x.get('Rating', 0)), reverse=True)
        
        logger.info(f"ğŸ¯ Total restaurants found: {len(results)}")
        return results[:max_results]
        
    except Exception as e:
        logger.error(f"âŒ Error in restaurant search: {e}")
        return []

def format_restaurant_response(results: List[Dict], search_term: str) -> str:
    """Format restaurant search results with exact metro routes from CSV"""
    if not results:
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø·Ø§Ø¹Ù… ØªØ·Ø§Ø¨Ù‚ '{search_term}' ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
    
    response_parts = []
    
    if len(results) == 1:
        restaurant = results[0]
        response_parts.append(f"ÙˆØ¬Ø¯Øª Ù„Ùƒ Ù…Ø·Ø¹Ù… {restaurant.get('Name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Add rating if available
        if restaurant.get('Rating'):
            rating = float(restaurant['Rating'])
            response_parts.append(f"Ø¨ØªÙ‚ÙŠÙŠÙ… {rating:.1f}")
        
        # Add cuisine type
        if restaurant.get('type'):
            response_parts.append(f"ÙŠÙ‚Ø¯Ù… {restaurant['type']}")
        
        # Add price range
        if restaurant.get('price'):
            response_parts.append(f"ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø± {restaurant['price']}")
        
        # Add exact metro route from CSV
        if restaurant.get('Path'):
            response_parts.append(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø¨Ø§Ù„Ù…ØªØ±Ùˆ: {restaurant['Path']}")
        
        # Add duration if available
        if restaurant.get('Duration(m)'):
            duration = int(restaurant['Duration(m)'])
            response_parts.append(f"Ø§Ù„Ù…Ø¯Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ {duration} Ø¯Ù‚ÙŠÙ‚Ø©")
            
    else:
        response_parts.append(f"ÙˆØ¬Ø¯Øª Ù„Ùƒ {len(results)} Ù…Ø·Ø§Ø¹Ù…:")
        
        for i, restaurant in enumerate(results, 1):
            name = restaurant.get('Name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            rating = restaurant.get('Rating', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            cuisine = restaurant.get('type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            price = restaurant.get('price', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            
            restaurant_info = f"{i}. {name}"
            if rating != 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯':
                restaurant_info += f" (ØªÙ‚ÙŠÙŠÙ… {float(rating):.1f})"
            restaurant_info += f" - {cuisine} - {price}"
            
            # Add metro route for each restaurant
            if restaurant.get('Path'):
                restaurant_info += f" - Ø§Ù„Ù…Ø³Ø§Ø±: {restaurant['Path']}"
            
            response_parts.append(restaurant_info)
    
    return ". ".join(response_parts) + "."

# â”€â”€â”€ Gemini Live Audio System â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AudioManager:
    """Enhanced audio manager for real-time Gemini Live streaming"""
    def __init__(self):
        self.pya = None
        self.input_stream = None
        self.output_stream = None
        self.audio_queue = deque()
        self.playback_task = None
        
        # Audio settings optimized for Gemini Live and Raspberry Pi
        self.FORMAT = pyaudio.paInt16 if PYAUDIO_AVAILABLE else None
        self.CHANNELS = 1
        self.SEND_SAMPLE_RATE = 16000
        self.RECEIVE_SAMPLE_RATE = 24000
        
        # Adjust buffer size based on platform
        if RUNNING_ON_PI:
            self.CHUNK_SIZE = 1024  # Smaller buffer for Pi to reduce latency
            logger.info("ğŸ“ Using Pi-optimized audio settings")
        else:
            self.CHUNK_SIZE = 2048  # Larger buffer for desktop to prevent underruns

    async def initialize(self):
        """Initialize audio streams for real-time processing"""
        try:
            if PYAUDIO_AVAILABLE:
                self.pya = pyaudio.PyAudio()
                
                # Get microphone info
                mic_info = self.pya.get_default_input_device_info()
                logger.info(f"ğŸ¤ Microphone: {mic_info['name']}")

                # Initialize input stream for microphone
                self.input_stream = await asyncio.to_thread(
                    self.pya.open,
                    format=self.FORMAT,
                    channels=self.CHANNELS,
                    rate=self.SEND_SAMPLE_RATE,
                    input=True,
                    frames_per_buffer=self.CHUNK_SIZE * 2,  # Ù…Ø¶Ø§Ø¹ÙØ© buffer Ù„Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
                )

                # Initialize output stream for speakers
                self.output_stream = await asyncio.to_thread(
                    self.pya.open,
                    format=self.FORMAT,
                    channels=self.CHANNELS,
                    rate=self.RECEIVE_SAMPLE_RATE,
                    output=True,
                )
                
                logger.info("âœ… Real-time audio streams initialized successfully")
            else:
                logger.info("âœ… Using sounddevice fallback for audio")
                
        except Exception as e:
            logger.error(f"âŒ Audio initialization failed: {e}")
            raise

    def add_audio(self, audio_data):
        """Add audio data to playback queue"""
        self.audio_queue.append(audio_data)
        if self.playback_task is None or self.playback_task.done():
            self.playback_task = asyncio.create_task(self._play_audio())

    async def _play_audio(self):
        """Play audio from queue with real-time streaming and immediate state updates"""
        global speaking
        
        # Set speaking state immediately
        with state_lock:
            speaking = True
        
        logger.info("ğŸ—£ï¸ Gemini speaking - Video should switch to speaking mode")
        
        try:
            while self.audio_queue:
                try:
                    audio_data = self.audio_queue.popleft()
                    if PYAUDIO_AVAILABLE and self.output_stream:
                        await asyncio.to_thread(self.output_stream.write, audio_data)
                    else:
                        # Fallback to pygame/soundfile
                        await self._play_with_pygame(audio_data)
                except Exception as e:
                    logger.error(f"âŒ Audio playback error: {e}")
                    break
        finally:
            # Always reset speaking state when done
            with state_lock:
                speaking = False
            logger.info("âœ… Gemini finished speaking - Video should switch to silent mode")

    async def _play_with_pygame(self, audio_data):
        """Fallback audio playback using pygame"""
        try:
            # Convert audio data to playable format
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                sf.write(tmp_file.name, np.frombuffer(audio_data, dtype=np.int16), self.RECEIVE_SAMPLE_RATE)
                
                if not pygame.mixer.get_init():
                    pygame.mixer.init(frequency=self.RECEIVE_SAMPLE_RATE, size=-16, channels=1, buffer=4096)  # Ø²ÙŠØ§Ø¯Ø© buffer Ù„Ù…Ù†Ø¹ ALSA underrun
                
                pygame.mixer.music.load(tmp_file.name)
                pygame.mixer.music.play()
                
                while pygame.mixer.music.get_busy():
                    await asyncio.sleep(0.01)
                    
                os.unlink(tmp_file.name)
                
        except Exception as e:
            logger.error(f"âŒ Pygame audio playback error: {e}")

    async def read_audio_chunk(self):
        """Read audio chunk from microphone"""
        try:
            if PYAUDIO_AVAILABLE and self.input_stream:
                data = await asyncio.to_thread(
                    self.input_stream.read,
                    self.CHUNK_SIZE,
                    exception_on_overflow=False,
                )
                return data
            else:
                # Fallback to sounddevice
                import sounddevice as sd
                duration = self.CHUNK_SIZE / self.SEND_SAMPLE_RATE
                audio = sd.rec(int(duration * self.SEND_SAMPLE_RATE), 
                             samplerate=self.SEND_SAMPLE_RATE, 
                             channels=1, 
                             dtype=np.int16)
                sd.wait()
                return audio.tobytes()
        except Exception as e:
            logger.error(f"âŒ Audio read error: {e}")
            return None

    def cleanup(self):
        """Clean up audio resources"""
        try:
            if PYAUDIO_AVAILABLE and self.pya:
                if self.input_stream:
                    self.input_stream.stop_stream()
                    self.input_stream.close()
                if self.output_stream:
                    self.output_stream.stop_stream()
                    self.output_stream.close()
                self.pya.terminate()
            logger.info("ğŸ§¹ Audio cleanup completed")
        except Exception as e:
            logger.error(f"âŒ Audio cleanup error: {e}")

class GeminiLiveSession:
    """Fast, real-time Gemini Live session with immediate audio response"""
    def __init__(self):
        self.session = None
        self.session_context = None
        self.audio_manager = None
        self.running = False
        self.greeting_sent = False
        self.greeting_requested = False

    async def start(self):
        """Start fast Gemini Live session with real-time audio streaming"""
        global gemini_session, current_route
        
        try:
            # Initialize high-performance audio manager
            self.audio_manager = AudioManager()
            await self.audio_manager.initialize()
            
            # Enhanced system prompt for fast restaurant search
            from google.genai.types import LiveConnectConfig, SpeechConfig, VoiceConfig, PrebuiltVoiceConfig
            
            config = LiveConnectConfig(
                response_modalities=["AUDIO"],
                speech_config=SpeechConfig(
                    voice_config=VoiceConfig(
                        prebuilt_voice_config=PrebuiltVoiceConfig(voice_name="Charon")
                    )
                ),
                system_instruction=GEMINI_LIVE_SYSTEM_PROMPT
            )
            
            logger.info("ğŸš€ Starting fast Gemini Live session...")
            
            # Create session context with proper async handling
            self.session_context = client.aio.live.connect(model="gemini-2.5-flash-preview-native-audio-dialog", config=config)
            self.session = await self.session_context.__aenter__()
            
            logger.info("âœ… Fast Gemini Live connected! Real-time voice interaction ready")
            
            self.running = True
            gemini_session = self
            
            # Start high-performance concurrent tasks
            await asyncio.gather(
                self._process_and_send_audio(),
                self._receive_and_play(),
                self._check_greeting_requests()
            )
                
        except Exception as e:
            logger.error(f"âŒ Fast Gemini Live session error: {e}")
            await self.stop()

    async def _process_and_send_audio(self):
        """Process and send audio to Gemini in real-time with listening state updates"""
        global listening, speaking
        logger.info("ğŸ¤ Starting continuous audio processing...")
        
        while self.running:  # Always listen, not just when system_active
            try:
                # Update listening state when not speaking
                with state_lock:
                    if not speaking:
                        listening = True
                    else:
                        listening = False
                
                data = await self.audio_manager.read_audio_chunk()
                if data and self.session:
                    from google.genai.types import Blob
                    await self.session.send_realtime_input(
                        audio=Blob(data=data, mime_type="audio/pcm;rate=16000")
                    )
                    
            except Exception as e:
                logger.error(f"âŒ Audio send error: {e}")
                await asyncio.sleep(0.1)

    async def _receive_and_play(self):
        """Receive and play audio responses from Gemini immediately"""
        global current_route, listening
        
        while self.running:
            try:
                async for response in self.session.receive():
                    server_content = response.server_content

                    if (hasattr(server_content, "interrupted") and server_content.interrupted):
                        logger.info("ğŸ¤« Interruption detected")
                        # Reset listening state when interrupted
                        with state_lock:
                            listening = False

                    if server_content and server_content.model_turn:
                        # When Gemini starts responding, we're not listening anymore
                        with state_lock:
                            listening = False
                            
                        for part in server_content.model_turn.parts:
                            # Handle audio response immediately for fast playback
                            if part.inline_data:
                                self.audio_manager.add_audio(part.inline_data.data)
                            
                            # Handle text response for restaurant processing and RAG
                            if part.text:
                                text_content = part.text
                                logger.info(f"ğŸ“ Gemini: {text_content}")
                                
                                # Extract restaurant and search database
                                restaurant_name = self._extract_restaurant_from_text(text_content)
                                if restaurant_name:
                                    best_match, score = self._find_best_restaurant_match(restaurant_name)
                                    if best_match and score >= 40:
                                        # Process restaurant route
                                        self._process_restaurant_route(best_match)
                                
                                # Also try RAG system for enhanced responses
                                try:
                                    rag_response = ask_rag_question(text_content)
                                    if rag_response and "Ù„Ù„Ø£Ø³Ù" not in rag_response:
                                        logger.info(f"ğŸ§  RAG response: {rag_response[:100]}...")
                                except Exception as e:
                                    logger.debug(f"RAG processing error: {e}")

                    if server_content and server_content.turn_complete:
                        logger.info("âœ… Gemini turn complete - Ready to listen again")
                        # When Gemini finishes, we're ready to listen again
                        with state_lock:
                            listening = True
                        
            except Exception as e:
                logger.error(f"âŒ Response handling error: {e}")
                await asyncio.sleep(1)

    def _extract_restaurant_from_text(self, text: str) -> str:
        """Extract restaurant name from Gemini's response"""
        try:
            patterns = extract_restaurant_patterns()
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match[0] else (match[1] if len(match) > 1 else "")
                    
                    result = clean_extracted_text(match)
                    
                    if len(result) > 2:
                        logger.info(f"âœ… Restaurant extracted: '{result}'")
                        return result
            
            return ""
        except Exception as e:
            logger.error(f"Error extracting restaurant: {e}")
            return ""

    def _find_best_restaurant_match(self, query: str):
        """Find best restaurant match with enhanced scoring"""
        if not query.strip():
            return "", 0
        
        try:
            # Check shortcuts first
            shortcuts = get_restaurant_shortcuts()
            q_lower = query.lower()
            for shortcut, full_name in shortcuts.items():
                if shortcut.lower() in q_lower:
                    for _, row in restaurants_df.iterrows():
                        restaurant_name = str(row["Display_Name"])
                        if full_name.lower() in restaurant_name.lower():
                            logger.info(f"âœ… Shortcut match: {restaurant_name}")
                            return restaurant_name, 95
            
            # Fuzzy matching
            result = process.extractOne(query, restaurants_df["Display_Name"].tolist())
            return result if result else ("", 0)
        except Exception as e:
            logger.error(f"Error finding restaurant match: {e}")
            return "", 0

    def _process_restaurant_route(self, restaurant_name):
        """Process restaurant route and update global state"""
        global current_route, current_route_text
        
        try:
            matching_rows = restaurants_df[restaurants_df["Display_Name"] == restaurant_name]
            if not matching_rows.empty:
                row = matching_rows.iloc[0]
                instr = row["Path"]
                start = row["Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø·Ø©"]
                end = row["Final Station"]
                
                # Store route text for map generation
                current_route_text = instr
                
                stations = self._path_to_stations(instr, start, end)
                if len(stations) >= 2:
                    current_route = stations
                    logger.info(f"ğŸ—ºï¸ Route found: {stations}")
                    logger.info(f"ğŸ—ºï¸ Route text: {current_route_text}")
                    
                    # Print detailed results
                    print(f"\nğŸ¯ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø·Ø¹Ù…!")
                    print(f"ğŸ“ Ø§Ù„Ù…Ø·Ø¹Ù…: {restaurant_name}")
                    print(f"ğŸš‡ Ø§Ù„Ù…Ø³Ø§Ø±: {instr}")
                    print(f"ğŸš‰ Ø§Ù„Ù…Ø­Ø·Ø§Øª:")
                    for i, station in enumerate(stations, 1):
                        print(f"  {i}. {station}")
                    print("-" * 50)
                    
        except Exception as e:
            logger.error(f"Error processing restaurant route: {e}")

    def _path_to_stations(self, path_text: str, start: str, end: str) -> list[str]:
        """Extract stations from path text"""
        try:
            found = re.findall(r"Ù…Ø­Ø·Ø©\s*([\u0600-\u06FF0-9 ]+)", path_text)
            stations = [start]
            for nm in found:
                name = nm.strip()
                if name in (start, end) or name == "Ø§Ù„Ø­Ø§Ù„ÙŠØ©":
                    continue
                stations.append(name)
            stations.append(end)
            return stations
        except Exception as e:
            logger.error(f"Error extracting stations: {e}")
            return [start, end]

    async def _check_greeting_requests(self):
        """Check for greeting requests from one-shot face detection"""
        while self.running:
            try:
                if hasattr(self, 'greeting_requested') and self.greeting_requested and not self.greeting_sent:
                    logger.info("ğŸ‘‹ Greeting requested - sending automatic greeting")
                    await self.send_greeting(STRONG_GREETING)
                    self.greeting_sent = True
                    self.greeting_requested = False  # Reset flag
                    
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"âŒ Greeting check error: {e}")
                await asyncio.sleep(1)

    async def send_greeting(self, greeting_text: str):
        """Send greeting message to Gemini Live as system instruction"""
        try:
            if self.session:
                # Send as system message to trigger response
                system_message = f"Ù‚Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…: {greeting_text}"
                await self.session.send_realtime_input(text=system_message)
                logger.info("ğŸ‘‹ Greeting instruction sent to Gemini Live")
        except Exception as e:
            logger.error(f"âŒ Error sending greeting: {e}")

    async def stop(self):
        """Stop Gemini Live session and cleanup"""
        self.running = False
        
        if hasattr(self, 'session_context') and self.session_context:
            try:
                await self.session_context.__aexit__(None, None, None)
            except:
                pass
                
        if self.audio_manager:
            self.audio_manager.cleanup()
            
        logger.info("ğŸ›‘ Fast Gemini Live session stopped")

# â”€â”€â”€ Video Display System â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_video_frames():
    """Load video frames with enhanced error handling and frame validation"""
    silent_frames = []
    speaking_frames = []
    default_frame = None
    
    try:
        # Load silent video
        if os.path.exists("siraj_silent.mp4"):
            logger.info("ğŸ¬ Loading silent video...")
            cap_silent = cv2.VideoCapture("siraj_silent.mp4")
            if cap_silent.isOpened():
                frame_count = 0
                while True:
                    ret, frame = cap_silent.read()
                    if not ret:
                        break
                    frame_resized = resize_frame_to_fit(frame, max_size=(1280, 720))
                    silent_frames.append(frame_resized)
                    frame_count += 1
                cap_silent.release()
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(silent_frames)} Ø¥Ø·Ø§Ø± ØµØ§Ù…Øª")
            else:
                logger.warning("âŒ ÙØ´Ù„ ÙÙŠ ÙØªØ­ siraj_silent.mp4")
        else:
            logger.warning("âŒ Ù…Ù„Ù siraj_silent.mp4 ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        
        # Load speaking video
        if os.path.exists("siraj_speak2.mp4"):
            logger.info("ğŸ¬ Loading speaking video...")
            cap_speaking = cv2.VideoCapture("siraj_speak2.mp4")
            if cap_speaking.isOpened():
                frame_count = 0
                while True:
                    ret, frame = cap_speaking.read()
                    if not ret:
                        break
                    frame_resized = resize_frame_to_fit(frame, max_size=(1280, 720))
                    speaking_frames.append(frame_resized)
                    frame_count += 1
                cap_speaking.release()
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(speaking_frames)} Ø¥Ø·Ø§Ø± Ù…ØªØ­Ø¯Ø«")
            else:
                logger.warning("âŒ ÙØ´Ù„ ÙÙŠ ÙØªØ­ siraj_speak2.mp4")
        else:
            logger.warning("âŒ Ù…Ù„Ù siraj_speak2.mp4 ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        
        # Create default frame if videos fail
        if not silent_frames and not speaking_frames:
            default_frame = np.zeros((720, 1280, 3), dtype=np.uint8)
            cv2.putText(default_frame, "Siraj Metro Assistant", (400, 360), 
                       cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), 3)
            logger.info("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø·Ø§Ø± Ø§ÙØªØ±Ø§Ø¶ÙŠ")
        
        # If only one video is available, use it for both states
        if silent_frames and not speaking_frames:
            speaking_frames = silent_frames.copy()
            logger.info("â„¹ï¸ Using silent video for both states")
        elif speaking_frames and not silent_frames:
            silent_frames = speaking_frames.copy() 
            logger.info("â„¹ï¸ Using speaking video for both states")
        
        return silent_frames, speaking_frames, default_frame
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {e}")
        # Return default frame
        default_frame = np.zeros((720, 1280, 3), dtype=np.uint8)
        cv2.putText(default_frame, "Siraj Metro Assistant", (400, 360), 
                   cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), 3)
        return [], [], default_frame

# â”€â”€â”€ Main Application â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    """Main application with Gemini Live integration - supports both Desktop and Raspberry Pi"""
    global system_active, person_present, current_route, gemini_session
    
    logger.info("ğŸš€ Starting Siraj - Clean Gemini Live Solution")
    
    # GPIO disabled by user request (user has screen display)
    # if RUNNING_ON_PI and GPIO_AVAILABLE:
    #     if not initialize_gpio():
    #         logger.warning("âš ï¸ GPIO initialization failed - continuing without hardware controls")
    logger.info("ğŸ›ï¸ GPIO controls disabled - using screen display interface")
    
    # Load data
    if not load_and_process_data():
        logger.error("âŒ Failed to load restaurant data")
        return
    
    # Initialize RAG system
    initialize_rag_system()
    
    # Initialize face detection
    face_detection_available = initialize_face_detection()
    if face_detection_available:
        logger.info("âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡")
    else:
        logger.warning("âš ï¸ ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ØºÙŠØ± Ù…ØªØ§Ø­")
    
    # Check if running headless mode (only when absolutely necessary)
    no_display = os.environ.get('DISPLAY') is None
    ssh_session = os.environ.get('SSH_CLIENT') is not None or os.environ.get('SSH_TTY') is not None
    forced_headless = os.getenv("SIRAJ_HEADLESS", "false").lower() == "true"
    
    # Only force headless if explicitly requested or no display available
    headless_mode = forced_headless or (no_display and ssh_session)
    
    if RUNNING_ON_PI and not headless_mode:
        logger.info("ğŸ“ Raspberry Pi detected with display - running GUI mode")
    if no_display and ssh_session:
        logger.info("ğŸ–¥ï¸ No DISPLAY + SSH detected - forcing headless mode")
    if forced_headless:
        logger.info("âš™ï¸ SIRAJ_HEADLESS=true - forcing headless mode")
    
    if headless_mode:
        logger.info("ğŸ–¥ï¸ Running in headless mode (no GUI)")
        run_headless_mode()
    else:
        logger.info("ğŸ–¥ï¸ Running in desktop mode (with GUI)")
        run_desktop_mode()

def run_headless_mode():
    """Run Siraj in headless mode for Raspberry Pi"""
    global system_active, person_present, gemini_session
    
    # Initialize Gemini Live session
    gemini_session = GeminiLiveSession()
    
    # Start Gemini Live in background thread
    def start_gemini_live():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(gemini_session.start())
        loop.run_forever()
    
    gemini_thread = threading.Thread(target=start_gemini_live, daemon=True)
    gemini_thread.start()
    logger.info("ğŸ¤ Gemini Live started in background thread")
    
    # Wait a moment for the session to initialize
    time.sleep(3)
    
    # Start camera monitoring for face detection
    def run_one_shot_detection():
        time.sleep(2)  # Wait for Gemini session to initialize
        one_shot_face_detection(timeout_s=5.0)
    
    detection_thread = threading.Thread(target=run_one_shot_detection, daemon=True)
    detection_thread.start()
    
    # Set system active for Raspberry Pi
    system_active = True
    person_present = True
    
    # Status LED disabled - using screen display instead
    # set_status_led(True)
    
    logger.info("âœ… Siraj ready for voice interaction on Raspberry Pi!")
    logger.info("ğŸ–¥ï¸ Screen display mode - GPIO controls disabled")
    logger.info("ğŸ“± Press Ctrl+C to stop")
    
    try:
        # Simple monitoring loop for headless mode
        while True:
            time.sleep(1)
            
            # Status LED updates disabled - using screen display instead
            # if speaking:
            #     set_status_led(True)
            # elif listening:
            #     # Blink LED when listening
            #     set_status_led(True)
            #     time.sleep(0.1)
            #     set_status_led(False)
            #     time.sleep(0.1)
            # else:
            #     set_status_led(system_active)
            pass
                
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Headless mode shutdown requested")
    
    finally:
        # Cleanup
        try:
            def stop_session_sync():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(gemini_session.stop())
                loop.close()
            
            stop_thread = threading.Thread(target=stop_session_sync)
            stop_thread.start()
            stop_thread.join(timeout=5)  # Wait max 5 seconds
            
            # cleanup_gpio()  # GPIO disabled
            
        except Exception as e:
            logger.error(f"Error during headless cleanup: {e}")
        
        logger.info("ğŸ‘‹ Siraj headless shutdown complete")

def run_desktop_mode():
    """Run Siraj in desktop mode with GUI"""
    global system_active, person_present, current_route, gemini_session
    
    # Load video frames
    silent_frames, speaking_frames, default_frame = load_video_frames()
    
    # Create GUI for full screen display
    sg.theme('DarkBlue3')
    
    layout = [
        [sg.Image(key="VIDEO", size=(1280, 720))],  # Full screen video
    ]
    
    window = sg.Window(
        "Siraj Metro Assistant",
        layout,
        finalize=True,
        resizable=False,
        location=(0, 0),     # Top-left corner
        size=(1280, 720),    # Full HD resolution
        no_titlebar=True,    # Remove title bar for full screen
        keep_on_top=True,    # Keep on top
        margins=(0, 0),      # No margins for full screen
        grab_anywhere=True   # Allow dragging for positioning
    )
    
    # Initialize Gemini Live session
    gemini_session = GeminiLiveSession()
    
    # Start background tasks
    def start_gemini_live():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(gemini_session.start())
        loop.run_forever()
    
    gemini_thread = threading.Thread(target=start_gemini_live, daemon=True)
    gemini_thread.start()
    logger.info("ğŸ¤ ØªÙ… Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬ Gemini Live ÙÙŠ thread Ù…Ù†ÙØµÙ„")
    
    # Wait a moment for the session to initialize
    time.sleep(3)
    logger.info(f"ğŸ” Ø­Ø§Ù„Ø© Gemini session: {gemini_session is not None}")
    logger.info(f"ğŸ” Ø­Ø§Ù„Ø© Gemini session running: {gemini_session.running if gemini_session else False}")
    logger.info(f"ğŸ” GEMINI_LIVE_AVAILABLE: {GEMINI_LIVE_AVAILABLE}")
    
    # Start camera monitoring
    # One-shot face detection at startup only
    def run_one_shot_detection():
        time.sleep(2)  # Wait for Gemini session to initialize
        one_shot_face_detection(timeout_s=5.0)
    
    detection_thread = threading.Thread(target=run_one_shot_detection, daemon=True)
    detection_thread.start()
    
    # Advanced person detection removed - using one-shot detection only
    logger.info("ğŸ¥ Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ´Ù Ø§Ù„ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· - Ù„Ø§ ØªÙˆØ¬Ø¯ Ø®ÙŠÙˆØ· ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø³ØªÙ…Ø±Ø©")
    
    # Video display variables
    frame_index_silent = 0
    frame_index_speaking = 0
    last_frame_time = time.time()
    current_video_state = "silent"  # Track current video state
    
    # Initial status - always active for continuous conversation
    system_active = True
    person_present = True
    
    logger.info(f"ğŸ¬ Video frames loaded - Silent: {len(silent_frames)}, Speaking: {len(speaking_frames)}")
    
    try:
        while True:
            event, values = window.read(timeout=30)  # Faster update rate
            
            if event in (sg.WIN_CLOSED, "EXIT"):
                break
            
            # No button events to handle - clean interface for touch screen
            
            # Update video display
            current_time = time.time()
            if current_time - last_frame_time > 0.025:  # ~40 FPS for smoother video
                
                frame = None
                status_color = (255, 255, 255)
                status_text = "âš¡ Ø³Ø±Ø§Ø¬ Ø¬Ø§Ù‡Ø²"
                
                # Choose frame based on state with immediate switching
                with state_lock:
                    current_speaking = speaking
                    current_listening = listening
                
                if current_speaking and speaking_frames:
                    # Speaking state - use speaking video
                    frame = speaking_frames[frame_index_speaking % len(speaking_frames)]
                    frame_index_speaking += 1
                    status_color = (0, 255, 0)  # Green for speaking
                    status_text = "ğŸ—£ï¸ Ø³Ø±Ø§Ø¬ ÙŠØªØ­Ø¯Ø«"
                    if current_video_state != "speaking":
                        current_video_state = "speaking"
                        frame_index_speaking = 0  # Reset frame index when switching
                        logger.info("ğŸ¬ ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ÙƒÙ„Ø§Ù…")
                
                elif current_listening and silent_frames:
                    # Listening state - use silent video
                    frame = silent_frames[frame_index_silent % len(silent_frames)]
                    frame_index_silent += 1
                    status_color = (255, 255, 0)  # Yellow for listening
                    status_text = "ğŸ‘‚ Ø³Ø±Ø§Ø¬ ÙŠØ³ØªÙ…Ø¹"
                    if current_video_state != "listening":
                        current_video_state = "listening"
                        frame_index_silent = 0  # Reset frame index when switching
                        logger.info("ğŸ¬ ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹")
                
                else:
                    # Ready/Idle state - use silent video
                    if silent_frames:
                        frame = silent_frames[frame_index_silent % len(silent_frames)]
                        frame_index_silent += 1
                    else:
                        frame = default_frame
                    status_color = (255, 255, 255)  # White for ready
                    status_text = "âš¡ Ø³Ø±Ø§Ø¬ Ø¬Ø§Ù‡Ø²"
                    if current_video_state != "silent":
                        current_video_state = "silent"
                        frame_index_silent = 0  # Reset frame index when switching
                        logger.info("ğŸ¬ ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ØµÙ…Øª")
                
                # Add status overlay to frame
                if frame is not None:
                    # Create a copy to avoid modifying original
                    display_frame = frame.copy()
                    
                    # Add status text overlay with larger, clearer display
                    cv2.rectangle(display_frame, (10, 10), (500, 80), (0, 0, 0), -1)  # Black background
                    cv2.rectangle(display_frame, (10, 10), (500, 80), status_color, 3)  # Colored border
                    
                    # Add current state text
                    state_text = "Speaking" if current_speaking else "Listening" if current_listening else "Ready"
                    cv2.putText(display_frame, f"State: {state_text}", 
                               (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
                    
                    # Add frame counter for debugging
                    if current_speaking and speaking_frames:
                        cv2.putText(display_frame, f"Speaking Frame: {frame_index_speaking}/{len(speaking_frames)}", 
                                   (20, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
                    elif silent_frames:
                        cv2.putText(display_frame, f"Silent Frame: {frame_index_silent}/{len(silent_frames)}", 
                                   (20, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
                    
                    # Add Gemini session status
                    gemini_status = "Connected" if (gemini_session and gemini_session.running) else "Disconnected"
                    cv2.putText(display_frame, f"Gemini: {gemini_status}", 
                               (20, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
                    
                    # Encode and display
                    imgbytes = cv2.imencode('.png', display_frame)[1].tobytes()
                    window["VIDEO"].update(data=imgbytes)
                
                last_frame_time = current_time
    
    except Exception as e:
        logger.error(f"âŒ Main loop error: {e}")
    
    finally:
        # Cleanup
        try:
            def stop_session_sync():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(gemini_session.stop())
                loop.close()
            
            stop_thread = threading.Thread(target=stop_session_sync)
            stop_thread.start()
            stop_thread.join(timeout=5)  # Wait max 5 seconds
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")
        
        window.close()
        # cleanup_gpio()  # GPIO disabled by user request
        logger.info("ğŸ‘‹ Siraj desktop shutdown complete")

def start_camera_monitor():
    """Simple camera monitoring with error handling"""
    global person_present, system_active
    
    try:
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            logger.warning("âŒ Camera not available - auto-activating")
            person_present = True
            system_active = True
            return
        
        # Try to load face cascade with error handling
        face_cascade = None
        try:
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            if face_cascade.empty():
                face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
                if face_cascade.empty():
                    face_cascade = None
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙƒØ§Ø´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙÙŠ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©: {e}")
            face_cascade = None
        
        if face_cascade is None:
            logger.warning("âŒ No face detection available - auto-activating")
            person_present = True
            system_active = True
            return
        
        while True:
            ret, frame = cap.read()
            if not ret:
                continue
            
            try:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = face_cascade.detectMultiScale(gray, 1.1, 4)
                
                person_present = len(faces) > 0
                system_active = person_present
            except Exception as e:
                logger.debug(f"Detection error in simple monitor: {e}")
                # Continue without detection
            
            time.sleep(0.1)
    
    except Exception as e:
        logger.error(f"Camera error: {e}")
        person_present = True
        system_active = True

# â”€â”€â”€ Metro Network and Map Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_metro_network(stations_gdf, lines_gdf):
    """Build metro network graph from GeoJSON data"""
    G = nx.Graph()
    
    # Add stations as nodes
    for _, station in stations_gdf.iterrows():
        G.add_node(
            station['metrostationnamear'],
            pos=(station.geometry.y, station.geometry.x),
            line=station['metroline'],
            type='station'
        )
    
    # Connect stations using actual line geometry
    for line_id in lines_gdf['metroline'].unique():
        line_geom = lines_gdf[lines_gdf['metroline'] == line_id].geometry.iloc[0]
        line_stations = stations_gdf[stations_gdf['metroline'] == line_id]
        
        if isinstance(line_geom, LineString) and len(line_stations) > 1:
            # Order stations by their position on the line
            stations_on_line = []
            for _, station in line_stations.iterrows():
                point = station.geometry
                progress = line_geom.project(point)
                stations_on_line.append({
                    'name': station['metrostationnamear'],
                    'progress': progress
                })
            
            ordered_stations = sorted(stations_on_line, key=lambda x: x['progress'])
            
            # Connect consecutive stations
            for i in range(len(ordered_stations)-1):
                start_station = ordered_stations[i]['name']
                end_station = ordered_stations[i+1]['name']
                
                # Create a simple connection
                G.add_edge(
                    start_station,
                    end_station,
                    line=line_id,
                    type='line_connection'
                )
    
    return G

def get_line_colors():
    """Get metro line colors"""
    return {
        'Metro 1': '#00ade5',
        'Metro 2': '#f0493a', 
        'Metro 3': '#f68d39',
        'Metro 4': '#ffd105',
        'Metro 5': '#43b649',
        'Metro 6': '#984c9d',
    }

def draw_metro_path_folium(G, start, end, via=[]):
    """Draw metro path using Folium for interactive map"""
    if not FOLIUM_AVAILABLE:
        logger.warning("Folium not available for interactive maps")
        return None
        
    try:
        full_path = [start] + via + [end]
        full_route = []
        total_distance = 0
        
        # Build complete route
        for i in range(len(full_path) - 1):
            try:
                segment = nx.shortest_path(G, source=full_path[i], target=full_path[i+1])
                full_route += segment[:-1]  # Avoid duplication
            except nx.NetworkXNoPath:
                logger.error(f"No path found between {full_path[i]} and {full_path[i+1]}")
                return None
        full_route.append(end)
        
        # Create map centered on start
        start_coord = G.nodes[start]['pos']
        m = folium.Map(location=start_coord, zoom_start=11, tiles='CartoDB Positron')
        
        line_colors = get_line_colors()
        
        # Draw route segments
        for i in range(len(full_route) - 1):
            u = full_route[i]
            v = full_route[i + 1]
            
            if G.has_edge(u, v):
                edge = G[u][v]
                color = line_colors.get(edge['line'], 'gray')
                
                # Get coordinates of both stations
                start_pos = G.nodes[u]['pos']
                end_pos = G.nodes[v]['pos']
                
                # Draw simple line between stations
                folium.PolyLine(
                    [start_pos, end_pos], 
                    color=color, 
                    weight=6, 
                    opacity=0.8
                ).add_to(m)
                
        return m
        
    except Exception as e:
        logger.error(f"Error creating Folium map: {e}")
        return None

def text_to_map(G, route_text):
    """Convert route text to interactive map"""
    try:
        start = ''
        end = ''
        via = []
        
        parts = route_text.split("ØŒ")
        for part in parts:
            if "Ø§Ù„Ù…Ø­Ø·Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©" in part:
                continue
            elif "Ø¨Ø¯Ù‘Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±" in part:
                station = part.split("Ù…Ø­Ø·Ø©")[1].split("Ø¨Ø¯Ù‘Ù„")[0].strip()
                via.append(station)
            elif "Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±" in part:
                station = ' '.join(part.split("Ø¥Ù„Ù‰")[0].split("Ù…Ø­Ø·Ø©")[-1].strip().split(" ")[:-1])
                via.append(station)
            elif "Ø£Ø®Ø±Ø¬ Ø¹Ù†Ø¯" in part:
                station = part.split("Ù…Ø­Ø·Ø©")[-1].strip().split('.')[0]
                end = station
        
        # Use default start if not specified
        if not start:
            start = "Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ù…ÙŠØ±Ø© Ù†ÙˆØ±Ø© 2"  # Default start station
            
        if end:
            return draw_metro_path_folium(G, start, end, via)
        else:
            logger.warning("No end station found in route text")
            return None
            
    except Exception as e:
        logger.error(f"Error parsing route text: {e}")
        return None

def render_map_as_array(route: list[str]):
    """Enhanced map rendering with window display instead of browser"""
    global metro_network, current_route_text
    
    try:
        logger.info(f"ğŸ—ºï¸ Attempting to render map for route: {route}")
        
        # Check if we have the necessary data
        if not metro_network:
            logger.warning("âŒ Metro network not available")
            return False
            
        if not route or len(route) < 2:
            logger.warning("âŒ Invalid route - need at least 2 stations")
            return False
        
        # Create map using OpenCV for window display
        logger.info("ğŸ—ºï¸ Creating map window...")
        success = draw_metro_map_opencv_window(metro_network, route)
        
        if success:
            logger.info("âœ… Map displayed in window")
            return True
        else:
            logger.warning("âŒ Failed to create map window")
            return False
        
    except Exception as e:
        logger.error(f"âŒ Map rendering error: {e}")
        import traceback
        logger.error(f"âŒ Full traceback: {traceback.format_exc()}")
        return False

def draw_metro_map_opencv_window(G, route):
    """Draw metro map using OpenCV in a window"""
    try:
        if not route or len(route) < 2:
            logger.warning("âŒ Invalid route for map display")
            return False
            
        # Find path
        full_route = []
        for i in range(len(route) - 1):
            try:
                segment = nx.shortest_path(G, source=route[i], target=route[i+1])
                full_route += segment[:-1]  # Avoid duplication
            except nx.NetworkXNoPath:
                logger.error(f"No path found between {route[i]} and {route[i+1]}")
                return False
        full_route.append(route[-1])
        
        logger.info(f"ğŸ“ Full route: {full_route[:3]}...{full_route[-3:]} ({len(full_route)} stations)")
        
        # Create image
        img_width, img_height = 1000, 700
        img = np.ones((img_height, img_width, 3), dtype=np.uint8) * 255
        
        # Get bounds for scaling
        all_positions = [G.nodes[node]['pos'] for node in G.nodes()]
        min_lat = min(pos[0] for pos in all_positions)
        max_lat = max(pos[0] for pos in all_positions)
        min_lon = min(pos[1] for pos in all_positions)
        max_lon = max(pos[1] for pos in all_positions)
        
        # Scale coordinates to image size
        def scale_coords(lat, lon):
            x = int((lon - min_lon) / (max_lon - min_lon) * (img_width - 100) + 50)
            y = int((max_lat - lat) / (max_lat - min_lat) * (img_height - 100) + 50)
            return x, y
        
        line_colors_bgr = {
            'Metro 1': (229, 173, 0),    # Blue
            'Metro 2': (58, 73, 240),    # Red
            'Metro 3': (57, 141, 246),   # Orange
            'Metro 4': (5, 209, 255),    # Yellow
            'Metro 5': (73, 182, 67),    # Green
            'Metro 6': (157, 76, 152),   # Purple
        }
        
        # Draw all metro lines (background)
        for u, v, data in G.edges(data=True):
            pos_u = scale_coords(*G.nodes[u]['pos'])
            pos_v = scale_coords(*G.nodes[v]['pos'])
            cv2.line(img, pos_u, pos_v, (200, 200, 200), 1)
        
        # Draw route segments (highlighted)
        for i in range(len(full_route) - 1):
            u = full_route[i]
            v = full_route[i + 1]
            
            if G.has_edge(u, v):
                edge = G[u][v]
                color = line_colors_bgr.get(edge['line'], (128, 128, 128))
                
                pos_u = scale_coords(*G.nodes[u]['pos'])
                pos_v = scale_coords(*G.nodes[v]['pos'])
                
                cv2.line(img, pos_u, pos_v, color, 4)
        
        # Draw all stations (small circles)
        for node in G.nodes():
            pos = scale_coords(*G.nodes[node]['pos'])
            cv2.circle(img, pos, 3, (180, 180, 180), -1)
        
        # Draw route stations (highlighted)
        for i, node in enumerate(full_route):
            pos = scale_coords(*G.nodes[node]['pos'])
            if i == 0:  # Start station
                cv2.circle(img, pos, 10, (0, 255, 0), -1)  # Green
                cv2.circle(img, pos, 10, (255, 255, 255), 2)  # White border
                cv2.putText(img, "START", (pos[0]-25, pos[1]-15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            elif i == len(full_route) - 1:  # End station
                cv2.circle(img, pos, 10, (0, 0, 255), -1)  # Red
                cv2.circle(img, pos, 10, (255, 255, 255), 2)  # White border
                cv2.putText(img, "END", (pos[0]-20, pos[1]-15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            else:  # Intermediate stations
                cv2.circle(img, pos, 6, (255, 0, 0), -1)  # Blue
                cv2.circle(img, pos, 6, (255, 255, 255), 1)  # White border
        
        # Add title and info
        cv2.putText(img, "Riyadh Metro Route Map", (50, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 2)
        cv2.putText(img, f"Route: {len(full_route)} stations", (50, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
        cv2.putText(img, "Press any key to close", (50, img_height - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 100, 100), 1)
        
        # Show the image in a separate thread to avoid blocking
        def show_map_window():
            cv2.imshow("Metro Route Map - Siraj", img)
            cv2.waitKey(5000)  # Show for 5 seconds or until key press
            cv2.destroyAllWindows()
        
        import threading
        map_thread = threading.Thread(target=show_map_window, daemon=True)
        map_thread.start()
        
        return True
        
    except Exception as e:
        logger.error(f"Error creating OpenCV map: {e}")
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")
        return False

# â”€â”€â”€ System Service Support for Raspberry Pi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_systemd_service():
    """Create systemd service for Raspberry Pi auto-start"""
    service_content = """[Unit]
Description=Siraj Arabic Voice Assistant for Riyadh Metro
After=network.target sound.target

[Service]
Type=simple
User=pi
WorkingDirectory=/home/pi/siraj_gemini
Environment=PATH=/home/pi/siraj_gemini/venv/bin
Environment=SIRAJ_HEADLESS=true
ExecStart=/home/pi/siraj_gemini/venv/bin/python /home/pi/siraj_gemini/full_inegration.py
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
"""
    
    try:
        with open('/tmp/siraj.service', 'w') as f:
            f.write(service_content)
        
        print("Service file created at /tmp/siraj.service")
        print("To install, run:")
        print("sudo cp /tmp/siraj.service /etc/systemd/system/")
        print("sudo systemctl daemon-reload")
        print("sudo systemctl enable siraj.service")
        print("sudo systemctl start siraj.service")
        
    except Exception as e:
        logger.error(f"Failed to create service file: {e}")

def print_pi_setup_commands():
    """Print setup commands for Raspberry Pi"""
    commands = """
ğŸ“ Raspberry Pi Setup Commands:

# Install system dependencies
sudo apt update && sudo apt upgrade -y
sudo apt install python3 python3-pip python3-venv git -y
sudo apt install libportaudio2 libportaudio-dev libasound2-dev -y
sudo apt install libopencv-dev python3-opencv -y

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install Python packages
pip install google-genai python-dotenv pandas opencv-python
pip install pyaudio pygame soundfile RPi.GPIO
pip install fuzzywuzzy python-Levenshtein loguru

# Set environment variables
echo "GEMINI_API_KEY=your_key_here" > .env
echo "SIRAJ_HEADLESS=true" >> .env

# Run Siraj
python3 full_inegration.py

# Or create systemd service
python3 -c "from full_inegration import create_systemd_service; create_systemd_service()"
"""
    print(commands)

if __name__ == "__main__":
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--create-service":
            create_systemd_service()
        elif sys.argv[1] == "--pi-setup":
            print_pi_setup_commands()
        elif sys.argv[1] == "--headless":
            os.environ["SIRAJ_HEADLESS"] = "true"
            main()
        else:
            print("Usage:")
            print("  python3 full_inegration.py                 # Normal mode")
            print("  python3 full_inegration.py --headless      # Headless mode")
            print("  python3 full_inegration.py --create-service # Create systemd service")
            print("  python3 full_inegration.py --pi-setup      # Show Pi setup commands")
    else:
        main() 